==>>> total trainning batch number: 469
==>>> total testing batch number: 79
Preference Vector (1/5):
[1.0000000e+00 1.5707963e-04]
fealsible solution is obtained.
1/100: weights=[0.24966848 0.75033146], train_loss=[2.6583304 1.2214919], train_acc=[0.17495 0.58945]
2/100: weights=[0.34009412 0.6599059 ], train_loss=[2.012685  0.9972661], train_acc=[0.3269  0.67095]
4/100: weights=[0.4247944  0.57520556], train_loss=[1.2459576  0.79373413], train_acc=[0.58455 0.73165]
6/100: weights=[0.17735107 0.8226489 ], train_loss=[0.9610995 0.7059648], train_acc=[0.68205 0.7662 ]
8/100: weights=[0.28882238 0.71117765], train_loss=[0.80238664 0.62539995], train_acc=[0.73825 0.79185]
10/100: weights=[0.2874078  0.71259224], train_loss=[0.7175799 0.6425793], train_acc=[0.76255 0.78315]
12/100: weights=[0.26896346 0.7310366 ], train_loss=[0.6609667  0.59371996], train_acc=[0.78395 0.79935]
14/100: weights=[0.43485707 0.565143  ], train_loss=[0.6127634  0.56242067], train_acc=[0.79985 0.81045]
16/100: weights=[0.5099262  0.49007386], train_loss=[0.5843958 0.5235605], train_acc=[0.80905 0.8246 ]
18/100: weights=[0.361252 0.638748], train_loss=[0.54625595 0.50922436], train_acc=[0.82045 0.8304 ]
20/100: weights=[0.25959662 0.74040335], train_loss=[0.52822894 0.48434758], train_acc=[0.826  0.8395]
22/100: weights=[0.32935548 0.6706445 ], train_loss=[0.50239414 0.47649178], train_acc=[0.8343  0.84315]
24/100: weights=[0.45070556 0.5492944 ], train_loss=[0.50124437 0.4621911 ], train_acc=[0.8343  0.84875]
26/100: weights=[0.24374312 0.75625694], train_loss=[0.47646877 0.4517471 ], train_acc=[0.84335 0.85495]
28/100: weights=[0.28314933 0.71685064], train_loss=[0.46619695 0.43776906], train_acc=[0.846  0.8565]
30/100: weights=[0.35990122 0.6400988 ], train_loss=[0.45955187 0.4406419 ], train_acc=[0.8471  0.85605]
32/100: weights=[0.37523073 0.62476933], train_loss=[0.44636098 0.4274242 ], train_acc=[0.8537 0.8594]
34/100: weights=[0.12382153 0.8761785 ], train_loss=[0.44498098 0.45042956], train_acc=[0.85335 0.852  ]
36/100: weights=[0.20445697 0.7955431 ], train_loss=[0.43432724 0.41913557], train_acc=[0.85795 0.8609 ]
38/100: weights=[0.22598022 0.7740198 ], train_loss=[0.42917532 0.4143858 ], train_acc=[0.8602  0.86365]
40/100: weights=[0.03196771 0.9680323 ], train_loss=[0.42101893 0.40642038], train_acc=[0.86135 0.8661 ]
42/100: weights=[-0.03526212  0.96473783], train_loss=[0.42125055 0.41191253], train_acc=[0.86145 0.86365]
44/100: weights=[0.3016321  0.69836795], train_loss=[0.4161092 0.4100241], train_acc=[0.8631  0.86385]
46/100: weights=[0.22333977 0.77666014], train_loss=[0.40670994 0.4012427 ], train_acc=[0.8652 0.8685]
48/100: weights=[0.24218816 0.75781184], train_loss=[0.40230334 0.38915846], train_acc=[0.8669 0.8708]
50/100: weights=[0.23841193 0.76158804], train_loss=[0.39841765 0.39852217], train_acc=[0.86795 0.8706 ]
52/100: weights=[0.4733549 0.5266451], train_loss=[0.39491954 0.39145544], train_acc=[0.86965 0.8694 ]
54/100: weights=[0.21004082 0.7899592 ], train_loss=[0.39363682 0.4013551 ], train_acc=[0.87045 0.8689 ]
56/100: weights=[0.36784706 0.632153  ], train_loss=[0.38938978 0.38350937], train_acc=[0.8712  0.87335]
58/100: weights=[0.5393348  0.46066517], train_loss=[0.39377797 0.37895748], train_acc=[0.8689 0.8747]
60/100: weights=[0.20827526 0.79172474], train_loss=[0.38559434 0.38330993], train_acc=[0.8724 0.8752]
62/100: weights=[0.310184 0.689816], train_loss=[0.38461044 0.38143307], train_acc=[0.8722 0.8755]
64/100: weights=[0.30844313 0.6915569 ], train_loss=[0.3783876  0.39205843], train_acc=[0.8741  0.87205]
66/100: weights=[0.12185764 0.87814236], train_loss=[0.37740362 0.378126  ], train_acc=[0.8762 0.876 ]
68/100: weights=[0.7126297  0.28737032], train_loss=[0.37587357 0.3727108 ], train_acc=[0.8768  0.87735]
70/100: weights=[0.25114003 0.74886   ], train_loss=[0.3710946 0.3662162], train_acc=[0.8767 0.8783]
72/100: weights=[0.03851612 0.9614839 ], train_loss=[0.3707634  0.38320458], train_acc=[0.87825 0.8735 ]
74/100: weights=[0.37501234 0.6249877 ], train_loss=[0.36917216 0.36287573], train_acc=[0.8787 0.8807]
76/100: weights=[0.38846838 0.61153156], train_loss=[0.37027717 0.37357736], train_acc=[0.87755 0.87735]
78/100: weights=[0.2783331  0.72166693], train_loss=[0.3644536  0.37964857], train_acc=[0.88065 0.8773 ]
80/100: weights=[0.35780814 0.6421919 ], train_loss=[0.36309978 0.3631822 ], train_acc=[0.88075 0.87955]
82/100: weights=[0.44737136 0.5526287 ], train_loss=[0.36020193 0.3622228 ], train_acc=[0.8798  0.88095]
84/100: weights=[0.35696492 0.6430352 ], train_loss=[0.3601388 0.363438 ], train_acc=[0.8809 0.8806]
86/100: weights=[0.05313519 0.9468648 ], train_loss=[0.36785507 0.39135656], train_acc=[0.8786  0.87435]
88/100: weights=[0.15237065 0.8476293 ], train_loss=[0.35488102 0.3633377 ], train_acc=[0.8833 0.8816]
90/100: weights=[0.19269483 0.8073052 ], train_loss=[0.35372135 0.36282933], train_acc=[0.88315 0.87955]
92/100: weights=[0.7652071  0.23479295], train_loss=[0.35227874 0.35035267], train_acc=[0.88485 0.88415]
94/100: weights=[0.17462829 0.82537174], train_loss=[0.34925324 0.35619584], train_acc=[0.8852  0.88505]
96/100: weights=[0.09356971 0.90643024], train_loss=[0.35198343 0.36094376], train_acc=[0.88165 0.8811 ]
98/100: weights=[0.26970997 0.73029006], train_loss=[0.3622666  0.37276116], train_acc=[0.87935 0.87775]
100/100: weights=[0.08666676 0.9133332 ], train_loss=[0.34708092 0.3552069 ], train_acc=[0.88585 0.88385]
Traceback (most recent call last):
  File "pmtl_train.py", line 386, in <module>
    run(dataset = 'mnist', base_model = 'lenet', niter = 100, npref = 5)
  File "pmtl_train.py", line 378, in run
    res = train(dataset, base_model, niter, npref, init_weight, pref_idx)
  File "pmtl_train.py", line 359, in train
    torch.save(model.model.state_dict(), './saved_model/%s_%s_niter_%d_npref_%d_prefidx_%d.pickle'%(dataset, base_model, niter, npref, pref_idx))
  File "/h/kelvin/software/anaconda3/envs/epo-cuda10/lib/python3.7/site-packages/torch/serialization.py", line 369, in save
    with _open_file_like(f, 'wb') as opened_file:
  File "/h/kelvin/software/anaconda3/envs/epo-cuda10/lib/python3.7/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/h/kelvin/software/anaconda3/envs/epo-cuda10/lib/python3.7/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './saved_model/mnist_lenet_niter_100_npref_5_prefidx_0.pickle'
