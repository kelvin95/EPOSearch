==>>> total trainning batch number: 469
==>>> total testing batch number: 79
1/100: weights=[0.22917227 0.7708277 ], train_loss=[1.8074546 1.1336423], train_acc=[0.36575 0.58185]
2/100: weights=[0.27261847 0.7273815 ], train_loss=[1.3662409 0.8992213], train_acc=[0.53655 0.6816 ]
4/100: weights=[0.56725574 0.43274426], train_loss=[1.0205982 0.8015165], train_acc=[0.6559  0.71145]
6/100: weights=[0.36206517 0.63793486], train_loss=[0.8486753 0.7343859], train_acc=[0.71905 0.7357 ]
8/100: weights=[0.24724865 0.75275135], train_loss=[0.7736002 0.7064149], train_acc=[0.7449  0.74455]
10/100: weights=[0.415954 0.584046], train_loss=[0.72283095 0.67011297], train_acc=[0.76025 0.758  ]
12/100: weights=[0.14148273 0.8585173 ], train_loss=[0.6620409 0.6488913], train_acc=[0.78385 0.7693 ]
14/100: weights=[0.51060665 0.48939338], train_loss=[0.6424479  0.63019025], train_acc=[0.78875 0.7729 ]
16/100: weights=[0.07793012 0.9220699 ], train_loss=[0.5961458 0.6409415], train_acc=[0.8061  0.76405]
18/100: weights=[0.28116482 0.7188352 ], train_loss=[0.5729367  0.60615593], train_acc=[0.81525 0.78115]
20/100: weights=[0.6800012  0.31999877], train_loss=[0.5492289  0.58889234], train_acc=[0.8209  0.78495]
22/100: weights=[0.4379433 0.5620567], train_loss=[0.581086  0.6024144], train_acc=[0.80775 0.77745]
24/100: weights=[0.42938998 0.57061005], train_loss=[0.5276109 0.5698367], train_acc=[0.82985 0.79625]
26/100: weights=[0.3779731 0.6220269], train_loss=[0.5939694 0.5852784], train_acc=[0.804  0.7876]
28/100: weights=[0.457057 0.542943], train_loss=[0.5017477  0.55371296], train_acc=[0.83845 0.8    ]
30/100: weights=[0.3073942 0.6926058], train_loss=[0.49628454 0.55032283], train_acc=[0.8372  0.80285]
32/100: weights=[0.6035619  0.39643812], train_loss=[0.49073657 0.5455855 ], train_acc=[0.83945 0.8015 ]
34/100: weights=[0.46929452 0.53070545], train_loss=[0.46670252 0.5389446 ], train_acc=[0.8499  0.80765]
36/100: weights=[0.7018325  0.29816753], train_loss=[0.54743767 0.5341847 ], train_acc=[0.81675 0.8045 ]
38/100: weights=[0.52738875 0.47261122], train_loss=[0.45201546 0.52519757], train_acc=[0.8537  0.81165]
40/100: weights=[0.33037177 0.66962826], train_loss=[0.44554034 0.52550346], train_acc=[0.85595 0.8114 ]
42/100: weights=[0.27570084 0.72429913], train_loss=[0.4442642 0.5349551], train_acc=[0.8583  0.80695]
44/100: weights=[0.04219198 0.957808  ], train_loss=[0.4346859 0.5152846], train_acc=[0.8606  0.81425]
46/100: weights=[0.03328703 0.96671295], train_loss=[0.43481165 0.5148419 ], train_acc=[0.8589  0.81275]
48/100: weights=[0.70844847 0.2915515 ], train_loss=[0.44562924 0.51140195], train_acc=[0.8549 0.8167]
50/100: weights=[0.27686256 0.72313744], train_loss=[0.42418188 0.50815976], train_acc=[0.86455 0.81825]
52/100: weights=[0.2068569 0.7931431], train_loss=[0.42082557 0.50607216], train_acc=[0.86415 0.81995]
54/100: weights=[0.5599139  0.44008616], train_loss=[0.41227072 0.5006212 ], train_acc=[0.8663 0.8182]
56/100: weights=[0.15261692 0.8473831 ], train_loss=[0.40708837 0.49958637], train_acc=[0.869   0.82005]
58/100: weights=[0.09915756 0.9008424 ], train_loss=[0.39868572 0.49753088], train_acc=[0.87285 0.82245]
60/100: weights=[0.2339343 0.7660657], train_loss=[0.4166725  0.50514346], train_acc=[0.86745 0.8163 ]
62/100: weights=[0.15453498 0.845465  ], train_loss=[0.4143658 0.5158907], train_acc=[0.8659 0.8093]
64/100: weights=[0.30500937 0.69499063], train_loss=[0.39039657 0.49169242], train_acc=[0.8733 0.8229]
66/100: weights=[0.3386816  0.66131836], train_loss=[0.4144802  0.49445814], train_acc=[0.86455 0.8229 ]
68/100: weights=[0.5752918  0.42470816], train_loss=[0.39468163 0.49121884], train_acc=[0.8734 0.8224]
70/100: weights=[0.35079965 0.6492003 ], train_loss=[0.39271075 0.5009381 ], train_acc=[0.87405 0.82355]
72/100: weights=[0.30820322 0.6917968 ], train_loss=[0.3798204  0.49582088], train_acc=[0.8789  0.82095]
74/100: weights=[0.594691   0.40530902], train_loss=[0.37740493 0.47937557], train_acc=[0.8777  0.82765]
76/100: weights=[0.4871374 0.5128626], train_loss=[0.37835214 0.48055953], train_acc=[0.8765 0.8279]
78/100: weights=[0.32118165 0.67881835], train_loss=[0.3888046 0.4854975], train_acc=[0.8728 0.8245]
80/100: weights=[0.31233296 0.687667  ], train_loss=[0.3781072 0.4941519], train_acc=[0.8787  0.81985]
82/100: weights=[0.44629562 0.5537044 ], train_loss=[0.36443248 0.4882946 ], train_acc=[0.8841  0.82415]
84/100: weights=[0.54282176 0.4571782 ], train_loss=[0.41389355 0.4846616 ], train_acc=[0.86275 0.82265]
86/100: weights=[0.39652076 0.6034792 ], train_loss=[0.3644964  0.48344365], train_acc=[0.88355 0.82475]
88/100: weights=[0.26858845 0.7314116 ], train_loss=[0.35529116 0.4732053 ], train_acc=[0.88615 0.8306 ]
90/100: weights=[0.36819866 0.63180137], train_loss=[0.3706417  0.49181327], train_acc=[0.87995 0.823  ]
92/100: weights=[0.30778638 0.6922136 ], train_loss=[0.34955564 0.47998837], train_acc=[0.88965 0.8273 ]
94/100: weights=[0.19746202 0.802538  ], train_loss=[0.34422657 0.47333246], train_acc=[0.89135 0.82935]
96/100: weights=[0.09220716 0.90779287], train_loss=[0.35042006 0.47473702], train_acc=[0.88795 0.8302 ]
98/100: weights=[0.35359383 0.6464062 ], train_loss=[0.35177788 0.47162667], train_acc=[0.8872  0.83005]
100/100: weights=[0.40265784 0.59734213], train_loss=[0.38170627 0.4900616 ], train_acc=[0.87465 0.81975]
**** Time taken for fashion_and_mnist_2 = 2850.740626335144
==>>> total trainning batch number: 469
==>>> total testing batch number: 79
1/100: weights=[0.33247414 0.6675258 ], train_loss=[1.9952438 1.2764443], train_acc=[0.33175 0.52585]
2/100: weights=[0.16945769 0.8305423 ], train_loss=[1.5822875  0.98635906], train_acc=[0.45575 0.6266 ]
4/100: weights=[0.24439605 0.75560397], train_loss=[1.1480521  0.84197384], train_acc=[0.6173  0.68865]
6/100: weights=[0.551617   0.44838297], train_loss=[0.9323095  0.76075345], train_acc=[0.68985 0.71555]
8/100: weights=[0.23751853 0.76248145], train_loss=[0.7870947 0.7397773], train_acc=[0.7396 0.7288]
10/100: weights=[0.83751935 0.16248067], train_loss=[0.72226834 0.69325364], train_acc=[0.76245 0.74175]
12/100: weights=[0.19414033 0.8058597 ], train_loss=[0.644607   0.71526927], train_acc=[0.79045 0.73155]
14/100: weights=[0.27359927 0.72640073], train_loss=[0.6151234 0.6625996], train_acc=[0.7984  0.75195]
16/100: weights=[0.55026865 0.44973135], train_loss=[0.5940444 0.6438111], train_acc=[0.8071 0.7583]
18/100: weights=[0.56964314 0.43035683], train_loss=[0.57952446 0.6218656 ], train_acc=[0.81045 0.7665 ]
20/100: weights=[0.41047478 0.5895252 ], train_loss=[0.5264826  0.61399287], train_acc=[0.8307  0.77185]
22/100: weights=[0.42081353 0.57918644], train_loss=[0.51942223 0.614307  ], train_acc=[0.83125 0.77165]
24/100: weights=[0.18068169 0.8193183 ], train_loss=[0.48891953 0.58705974], train_acc=[0.8445 0.7826]
26/100: weights=[0.42821652 0.5717835 ], train_loss=[0.5076217 0.5805334], train_acc=[0.8359 0.7879]
28/100: weights=[0.42384535 0.57615465], train_loss=[0.49748307 0.57415867], train_acc=[0.84    0.78875]
30/100: weights=[0.23895545 0.76104456], train_loss=[0.45869023 0.576261  ], train_acc=[0.85075 0.7876 ]
32/100: weights=[0.6069653 0.3930347], train_loss=[0.4725966 0.5670254], train_acc=[0.84595 0.79075]
34/100: weights=[0.32229668 0.6777033 ], train_loss=[0.44420987 0.5631093 ], train_acc=[0.857  0.7908]
36/100: weights=[0.29395765 0.70604235], train_loss=[0.43514383 0.5611915 ], train_acc=[0.85955 0.79365]
38/100: weights=[0.18791774 0.81208223], train_loss=[0.42051828 0.54890275], train_acc=[0.86415 0.79775]
40/100: weights=[0.3669528  0.63304716], train_loss=[0.42226383 0.5438629 ], train_acc=[0.8633 0.8003]
42/100: weights=[0.15478541 0.8452146 ], train_loss=[0.41184264 0.54883856], train_acc=[0.8658  0.79635]
44/100: weights=[0.2593999 0.7406001], train_loss=[0.41140592 0.55847824], train_acc=[0.86695 0.7985 ]
46/100: weights=[0.3376384  0.66236156], train_loss=[0.39580408 0.5387319 ], train_acc=[0.87305 0.80485]
48/100: weights=[0.6720069 0.3279931], train_loss=[0.40535197 0.5331207 ], train_acc=[0.8679  0.80555]
50/100: weights=[0.5554351  0.44456488], train_loss=[0.39974993 0.5284251 ], train_acc=[0.87145 0.8061 ]
52/100: weights=[0.19652794 0.80347204], train_loss=[0.40004483 0.5417771 ], train_acc=[0.86975 0.8008 ]
54/100: weights=[0.70615226 0.2938477 ], train_loss=[0.3827162 0.533303 ], train_acc=[0.87695 0.80545]
56/100: weights=[0.6995587  0.30044132], train_loss=[0.3940237  0.52441305], train_acc=[0.87275 0.8089 ]
58/100: weights=[0.22395454 0.77604544], train_loss=[0.37411293 0.5364952 ], train_acc=[0.87855 0.8021 ]
60/100: weights=[0.42461035 0.5753896 ], train_loss=[0.3838866  0.52597916], train_acc=[0.8737  0.80495]
62/100: weights=[0.291899 0.708101], train_loss=[0.37040904 0.51316315], train_acc=[0.8808 0.8127]
64/100: weights=[0.08586419 0.9141358 ], train_loss=[0.38700336 0.5165537 ], train_acc=[0.87425 0.811  ]
66/100: weights=[0.31033957 0.68966043], train_loss=[0.35975868 0.5190961 ], train_acc=[0.8846  0.81205]
68/100: weights=[0.49939275 0.50060725], train_loss=[0.36054993 0.50999683], train_acc=[0.8842  0.81165]
70/100: weights=[0.29129514 0.7087048 ], train_loss=[0.35885662 0.51150787], train_acc=[0.8834 0.8111]
72/100: weights=[0.39183614 0.6081639 ], train_loss=[0.35341266 0.5115073 ], train_acc=[0.8863 0.8153]
74/100: weights=[0.5849381  0.41506192], train_loss=[0.35985997 0.50548255], train_acc=[0.88485 0.81355]
76/100: weights=[0.6082036  0.39179638], train_loss=[0.36116165 0.50521946], train_acc=[0.88425 0.8149 ]
78/100: weights=[0.2926157 0.7073843], train_loss=[0.3476368  0.50278515], train_acc=[0.8879 0.8148]
80/100: weights=[0.4039765 0.5960235], train_loss=[0.34338266 0.5000216 ], train_acc=[0.8904  0.81835]
82/100: weights=[0.5227034 0.4772966], train_loss=[0.34587264 0.5053402 ], train_acc=[0.8878  0.81615]
84/100: weights=[0.27439386 0.72560614], train_loss=[0.3390925  0.50144976], train_acc=[0.88915 0.8175 ]
86/100: weights=[0.61096346 0.3890365 ], train_loss=[0.3486454 0.4926994], train_acc=[0.88685 0.821  ]
88/100: weights=[0.38229614 0.61770386], train_loss=[0.34497592 0.5016943 ], train_acc=[0.8879  0.81955]
90/100: weights=[0.5593506  0.44064936], train_loss=[0.34477472 0.49308002], train_acc=[0.8909 0.822 ]
92/100: weights=[0.33345115 0.66654885], train_loss=[0.3297438  0.50538564], train_acc=[0.89225 0.81505]
94/100: weights=[0.61631274 0.38368723], train_loss=[0.33891013 0.49294877], train_acc=[0.88955 0.822  ]
96/100: weights=[0.26701832 0.7329817 ], train_loss=[0.32945642 0.5030622 ], train_acc=[0.89235 0.814  ]
98/100: weights=[0.68687373 0.31312624], train_loss=[0.32972658 0.4912125 ], train_acc=[0.8936 0.8208]
100/100: weights=[0.4223013 0.5776987], train_loss=[0.33692116 0.49841103], train_acc=[0.8894 0.8203]
**** Time taken for fashion_and_mnist_3 = 2129.4718651771545
==>>> total trainning batch number: 469
==>>> total testing batch number: 79
1/100: weights=[0.5796695  0.42033052], train_loss=[1.7127156 1.0956709], train_acc=[0.40635 0.5831 ]
2/100: weights=[0.47109342 0.5289066 ], train_loss=[1.2381276 0.9123569], train_acc=[0.5853  0.66665]
4/100: weights=[0.55800694 0.44199306], train_loss=[0.9438496 0.7657318], train_acc=[0.6883  0.71705]
6/100: weights=[0.2064261 0.7935739], train_loss=[0.7979604 0.7337235], train_acc=[0.7383 0.7245]
8/100: weights=[0.12538512 0.8746149 ], train_loss=[0.6956762  0.70534647], train_acc=[0.77115 0.7315 ]
10/100: weights=[0.16110905 0.83889097], train_loss=[0.6654286  0.67223626], train_acc=[0.7823  0.75025]
12/100: weights=[0.50323987 0.49676013], train_loss=[0.6091394 0.6293782], train_acc=[0.7975 0.7673]
14/100: weights=[0.21072194 0.7892781 ], train_loss=[0.5876707  0.62736046], train_acc=[0.8096 0.7675]
16/100: weights=[0.15816963 0.8418304 ], train_loss=[0.5762931 0.6455906], train_acc=[0.81245 0.7621 ]
18/100: weights=[0.04047284 0.9595272 ], train_loss=[0.53555864 0.62051326], train_acc=[0.82455 0.76235]
20/100: weights=[0.41079423 0.58920574], train_loss=[0.52620125 0.58964103], train_acc=[0.82785 0.7763 ]
22/100: weights=[0.09560597 0.90439403], train_loss=[0.5076466  0.57665455], train_acc=[0.8341 0.7871]
24/100: weights=[0.21982847 0.7801715 ], train_loss=[0.5039265 0.5842488], train_acc=[0.83375 0.78065]
26/100: weights=[0.51701134 0.48298866], train_loss=[0.5075495  0.56175643], train_acc=[0.83345 0.78945]
28/100: weights=[0.4196841 0.5803159], train_loss=[0.47319472 0.55778956], train_acc=[0.84705 0.7927 ]
30/100: weights=[0.4471762 0.5528238], train_loss=[0.4706786 0.5476958], train_acc=[0.8481  0.79655]
32/100: weights=[0.33101246 0.6689875 ], train_loss=[0.45048562 0.5528583 ], train_acc=[0.8544  0.79255]
34/100: weights=[0.4613793 0.5386207], train_loss=[0.44809464 0.5365828 ], train_acc=[0.853  0.8011]
36/100: weights=[0.09778282 0.9022172 ], train_loss=[0.4258805  0.54248095], train_acc=[0.86345 0.7974 ]
38/100: weights=[0.65480334 0.34519666], train_loss=[0.4347186  0.54119074], train_acc=[0.8547  0.80115]
40/100: weights=[0.09587093 0.9041291 ], train_loss=[0.41788706 0.53513   ], train_acc=[0.86465 0.803  ]
42/100: weights=[0.11616641 0.8838336 ], train_loss=[0.40626976 0.5472786 ], train_acc=[0.86915 0.79445]
44/100: weights=[0.07257585 0.92742413], train_loss=[0.42505363 0.52843213], train_acc=[0.85995 0.80595]
46/100: weights=[0.02340227 0.9765977 ], train_loss=[0.40124968 0.5326393 ], train_acc=[0.8701  0.80225]
48/100: weights=[0.54766816 0.45233184], train_loss=[0.41284543 0.5194909 ], train_acc=[0.8662 0.8072]
50/100: weights=[0.08079528 0.9192047 ], train_loss=[0.38696483 0.5222491 ], train_acc=[0.87535 0.8071 ]
52/100: weights=[0.39072192 0.6092781 ], train_loss=[0.3907391 0.5129193], train_acc=[0.87215 0.8132 ]
54/100: weights=[0.01602678 0.9839732 ], train_loss=[0.394867  0.5331492], train_acc=[0.87265 0.7995 ]
56/100: weights=[0.2863702  0.71362984], train_loss=[0.39118817 0.51871186], train_acc=[0.8721  0.80495]
58/100: weights=[0.37862912 0.62137085], train_loss=[0.38790283 0.5038899 ], train_acc=[0.8725  0.81395]
60/100: weights=[0.423819 0.576181], train_loss=[0.37551308 0.5054514 ], train_acc=[0.8792 0.8149]
62/100: weights=[0.13762417 0.8623758 ], train_loss=[0.36294323 0.49827498], train_acc=[0.8814  0.81615]
64/100: weights=[0.55736905 0.44263095], train_loss=[0.3664841 0.5021001], train_acc=[0.881   0.81565]
66/100: weights=[0.26158598 0.73841405], train_loss=[0.3560706  0.49333674], train_acc=[0.88405 0.8179 ]
68/100: weights=[0.52828765 0.47171235], train_loss=[0.3869016  0.50554854], train_acc=[0.87325 0.8133 ]
70/100: weights=[0.4933232 0.5066768], train_loss=[0.35530615 0.49279875], train_acc=[0.88445 0.81965]
72/100: weights=[0.11952375 0.88047624], train_loss=[0.3499319  0.49088886], train_acc=[0.88635 0.8204 ]
74/100: weights=[0.3910712 0.6089288], train_loss=[0.35183606 0.50332075], train_acc=[0.88665 0.81495]
76/100: weights=[0.28874803 0.711252  ], train_loss=[0.35097945 0.49554884], train_acc=[0.88495 0.81675]
78/100: weights=[0.3996241 0.6003759], train_loss=[0.37037018 0.4919154 ], train_acc=[0.87765 0.8206 ]
80/100: weights=[0.14016536 0.8598346 ], train_loss=[0.33839235 0.4920679 ], train_acc=[0.88915 0.8214 ]
82/100: weights=[0.36869586 0.63130414], train_loss=[0.37176397 0.49562156], train_acc=[0.87725 0.8192 ]
84/100: weights=[0.40161052 0.59838945], train_loss=[0.34003156 0.48680308], train_acc=[0.88915 0.8212 ]
86/100: weights=[0.25693855 0.7430614 ], train_loss=[0.3388989 0.4937593], train_acc=[0.89055 0.8176 ]
88/100: weights=[0.33146042 0.6685396 ], train_loss=[0.35158417 0.4878995 ], train_acc=[0.8835  0.81955]
90/100: weights=[0.3112765 0.6887235], train_loss=[0.32924297 0.47900644], train_acc=[0.89415 0.82275]
92/100: weights=[0.22483006 0.77516997], train_loss=[0.33186573 0.48538977], train_acc=[0.8924 0.8231]
94/100: weights=[0.43369558 0.5663044 ], train_loss=[0.32837296 0.48921916], train_acc=[0.8943  0.81915]
96/100: weights=[0.17821355 0.82178646], train_loss=[0.35081616 0.48820814], train_acc=[0.8842  0.82255]
98/100: weights=[0.10682312 0.8931769 ], train_loss=[0.33459795 0.4748684 ], train_acc=[0.89135 0.82615]
100/100: weights=[0.06902759 0.9309724 ], train_loss=[0.3256452  0.48095843], train_acc=[0.89485 0.82575]
**** Time taken for fashion_and_mnist_4 = 1927.5707399845123
**** Time taken for fashion_and_mnist = 6907.907074213028
: invalid pointer
