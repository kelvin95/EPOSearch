==>>> total trainning batch number: 469
==>>> total testing batch number: 79
1/100: train_loss=[1.4080489 1.7759618], train_acc=[0.5207 0.3855]
2/100: train_loss=[1.0456067 1.3012046], train_acc=[0.6531 0.5681]
4/100: train_loss=[0.77543664 0.95271987], train_acc=[0.7465  0.68155]
6/100: train_loss=[0.67374593 0.83198106], train_acc=[0.77885 0.7186 ]
8/100: train_loss=[0.6148657  0.74794614], train_acc=[0.79725 0.7474 ]
10/100: train_loss=[0.5884721 0.6855223], train_acc=[0.80785 0.7666 ]
12/100: train_loss=[0.5393725 0.6322777], train_acc=[0.8225  0.78885]
14/100: train_loss=[0.5142087  0.60885006], train_acc=[0.8331 0.7971]
16/100: train_loss=[0.4871007  0.59099966], train_acc=[0.8397  0.80255]
18/100: train_loss=[0.47440436 0.569098  ], train_acc=[0.84205 0.81325]
20/100: train_loss=[0.45420086 0.55030304], train_acc=[0.85115 0.81545]
22/100: train_loss=[0.43998164 0.52128136], train_acc=[0.8555  0.82545]
24/100: train_loss=[0.43372002 0.5140571 ], train_acc=[0.8569  0.82775]
26/100: train_loss=[0.42774597 0.5022275 ], train_acc=[0.8592 0.8322]
28/100: train_loss=[0.4138059 0.4969469], train_acc=[0.86355 0.8349 ]
30/100: train_loss=[0.40931866 0.48452896], train_acc=[0.8658  0.83685]
32/100: train_loss=[0.398335  0.4776483], train_acc=[0.86985 0.8422 ]
34/100: train_loss=[0.42063403 0.4734609 ], train_acc=[0.86375 0.84275]
36/100: train_loss=[0.38425076 0.45665473], train_acc=[0.87345 0.8484 ]
38/100: train_loss=[0.38061267 0.45541015], train_acc=[0.87745 0.84875]
40/100: train_loss=[0.3830494  0.44235927], train_acc=[0.87665 0.853  ]
42/100: train_loss=[0.36886352 0.4409312 ], train_acc=[0.88025 0.8526 ]
44/100: train_loss=[0.36546022 0.43907824], train_acc=[0.88135 0.8534 ]
46/100: train_loss=[0.36462262 0.42709404], train_acc=[0.8816  0.85775]
48/100: train_loss=[0.3634336 0.4284333], train_acc=[0.88255 0.85645]
50/100: train_loss=[0.36045048 0.42257962], train_acc=[0.8846  0.86005]
52/100: train_loss=[0.36266786 0.41638246], train_acc=[0.88355 0.8627 ]
54/100: train_loss=[0.35131624 0.42337087], train_acc=[0.88725 0.85965]
56/100: train_loss=[0.3622619 0.422975 ], train_acc=[0.88175 0.8593 ]
58/100: train_loss=[0.3450981  0.40693128], train_acc=[0.88895 0.86545]
60/100: train_loss=[0.36073908 0.41353762], train_acc=[0.88315 0.862  ]
62/100: train_loss=[0.3423699  0.40775314], train_acc=[0.88865 0.8654 ]
64/100: train_loss=[0.36185622 0.40861237], train_acc=[0.88245 0.865  ]
66/100: train_loss=[0.34024632 0.40000975], train_acc=[0.89075 0.8674 ]
68/100: train_loss=[0.34880587 0.41188508], train_acc=[0.88565 0.8656 ]
70/100: train_loss=[0.3516885  0.39074475], train_acc=[0.8862  0.87055]
72/100: train_loss=[0.3357598  0.38813573], train_acc=[0.89195 0.87115]
74/100: train_loss=[0.33489323 0.38606796], train_acc=[0.89185 0.87235]
76/100: train_loss=[0.32914826 0.38611868], train_acc=[0.8931  0.87065]
78/100: train_loss=[0.32809237 0.39066997], train_acc=[0.8928  0.87055]
80/100: train_loss=[0.32575217 0.38643575], train_acc=[0.89345 0.8733 ]
82/100: train_loss=[0.33247998 0.3933658 ], train_acc=[0.89165 0.8694 ]
84/100: train_loss=[0.32759944 0.38189137], train_acc=[0.89375 0.87295]
86/100: train_loss=[0.32354307 0.38480574], train_acc=[0.89575 0.87115]
88/100: train_loss=[0.35838726 0.38903695], train_acc=[0.88395 0.8715 ]
90/100: train_loss=[0.32336083 0.37829828], train_acc=[0.89525 0.87515]
92/100: train_loss=[0.3206352  0.37226588], train_acc=[0.89525 0.87775]
94/100: train_loss=[0.32744148 0.38613033], train_acc=[0.89415 0.87405]
96/100: train_loss=[0.3419926  0.38057753], train_acc=[0.8908  0.87545]
98/100: train_loss=[0.31455895 0.37440637], train_acc=[0.89865 0.8746 ]
100/100: train_loss=[0.31762627 0.3716279 ], train_acc=[0.8961 0.8781]
**** Time taken for mnist_0 = 3997.9011042118073
==>>> total trainning batch number: 469
==>>> total testing batch number: 79
1/100: train_loss=[1.2851303 1.4904966], train_acc=[0.57265 0.49135]
2/100: train_loss=[0.9836202 1.0943602], train_acc=[0.67685 0.6347 ]
4/100: train_loss=[0.7375665 0.8135604], train_acc=[0.75955 0.7287 ]
6/100: train_loss=[0.6266306  0.70264804], train_acc=[0.79385 0.7632 ]
8/100: train_loss=[0.60117173 0.6297335 ], train_acc=[0.80305 0.7879 ]
10/100: train_loss=[0.53866726 0.6483271 ], train_acc=[0.8251 0.7804]
12/100: train_loss=[0.505933  0.5535115], train_acc=[0.83485 0.81335]
14/100: train_loss=[0.4642847 0.5352328], train_acc=[0.84885 0.8189 ]
16/100: train_loss=[0.45903638 0.5136126 ], train_acc=[0.84945 0.82695]
18/100: train_loss=[0.4280429 0.4880311], train_acc=[0.86025 0.835  ]
20/100: train_loss=[0.42439753 0.48589706], train_acc=[0.8612  0.83285]
22/100: train_loss=[0.4100902 0.4735221], train_acc=[0.8672  0.84035]
24/100: train_loss=[0.4111423  0.46429685], train_acc=[0.8643 0.8434]
26/100: train_loss=[0.38978118 0.45153174], train_acc=[0.87355 0.84905]
28/100: train_loss=[0.39281872 0.44209108], train_acc=[0.8699  0.85455]
30/100: train_loss=[0.37865153 0.4298979 ], train_acc=[0.8759 0.8549]
32/100: train_loss=[0.37163317 0.42252707], train_acc=[0.88005 0.8589 ]
34/100: train_loss=[0.36937183 0.43128163], train_acc=[0.87895 0.8558 ]
36/100: train_loss=[0.37186658 0.4555365 ], train_acc=[0.87935 0.8479 ]
38/100: train_loss=[0.3546172  0.41023758], train_acc=[0.88325 0.8633 ]
40/100: train_loss=[0.35594213 0.41794857], train_acc=[0.88255 0.8615 ]
42/100: train_loss=[0.34203935 0.41647765], train_acc=[0.8889  0.86175]
44/100: train_loss=[0.34701747 0.4070819 ], train_acc=[0.8866 0.8659]
46/100: train_loss=[0.34850332 0.41490242], train_acc=[0.88785 0.8618 ]
48/100: train_loss=[0.34339476 0.4081097 ], train_acc=[0.8867 0.865 ]
50/100: train_loss=[0.34062758 0.39473468], train_acc=[0.88595 0.86805]
52/100: train_loss=[0.3523848  0.39195797], train_acc=[0.88565 0.87005]
54/100: train_loss=[0.3257759  0.38401952], train_acc=[0.892   0.87105]
56/100: train_loss=[0.33241424 0.39863706], train_acc=[0.8903  0.86605]
58/100: train_loss=[0.3256673  0.40886974], train_acc=[0.8915 0.8627]
60/100: train_loss=[0.3265195  0.38596117], train_acc=[0.89375 0.8704 ]
62/100: train_loss=[0.31827155 0.37560242], train_acc=[0.89555 0.87435]
64/100: train_loss=[0.32652166 0.37720713], train_acc=[0.89235 0.87275]
66/100: train_loss=[0.3156546  0.38358027], train_acc=[0.89805 0.87195]
68/100: train_loss=[0.31301406 0.37230733], train_acc=[0.89655 0.87575]
70/100: train_loss=[0.31110775 0.3684827 ], train_acc=[0.89825 0.8775 ]
72/100: train_loss=[0.3219738 0.382591 ], train_acc=[0.89465 0.87275]
74/100: train_loss=[0.31355006 0.3671409 ], train_acc=[0.896   0.87885]
76/100: train_loss=[0.30665168 0.36845878], train_acc=[0.89945 0.87775]
78/100: train_loss=[0.30357003 0.35905668], train_acc=[0.9012  0.87955]
80/100: train_loss=[0.30538166 0.36512685], train_acc=[0.89885 0.87805]
82/100: train_loss=[0.29824492 0.3615016 ], train_acc=[0.902  0.8795]
84/100: train_loss=[0.29624695 0.36028975], train_acc=[0.90255 0.88065]
86/100: train_loss=[0.29752526 0.3837348 ], train_acc=[0.9023  0.87315]
88/100: train_loss=[0.29537916 0.3594106 ], train_acc=[0.90295 0.88035]
90/100: train_loss=[0.31597465 0.359571  ], train_acc=[0.89505 0.8812 ]
92/100: train_loss=[0.29834065 0.3596972 ], train_acc=[0.90185 0.8812 ]
94/100: train_loss=[0.29482043 0.35997292], train_acc=[0.90235 0.8814 ]
96/100: train_loss=[0.29693803 0.36151707], train_acc=[0.9019 0.8805]
98/100: train_loss=[0.29977697 0.34996602], train_acc=[0.9014 0.8849]
100/100: train_loss=[0.28971004 0.37449867], train_acc=[0.90555 0.87705]
**** Time taken for mnist_1 = 2928.052656888962
==>>> total trainning batch number: 469
==>>> total testing batch number: 79
1/100: train_loss=[1.3858733 1.7054567], train_acc=[0.53935 0.412  ]
2/100: train_loss=[0.94866925 1.1785463 ], train_acc=[0.69015 0.60145]
4/100: train_loss=[0.7076891  0.83548206], train_acc=[0.7721 0.7191]
6/100: train_loss=[0.56710404 0.6974269 ], train_acc=[0.81495 0.7698 ]
8/100: train_loss=[0.5056019 0.630253 ], train_acc=[0.8343 0.7929]
10/100: train_loss=[0.473727  0.5931045], train_acc=[0.84435 0.80125]
12/100: train_loss=[0.45873842 0.54691976], train_acc=[0.85095 0.81865]
14/100: train_loss=[0.43888563 0.54670566], train_acc=[0.85735 0.81845]
16/100: train_loss=[0.4201446  0.52080035], train_acc=[0.8612  0.82735]
18/100: train_loss=[0.40898028 0.4916324 ], train_acc=[0.86675 0.83635]
20/100: train_loss=[0.39094606 0.4906901 ], train_acc=[0.87115 0.83555]
22/100: train_loss=[0.3909022 0.4726405], train_acc=[0.87255 0.8434 ]
24/100: train_loss=[0.379631  0.4617536], train_acc=[0.87415 0.84485]
26/100: train_loss=[0.36446083 0.44933107], train_acc=[0.87935 0.85075]
28/100: train_loss=[0.35896656 0.44657174], train_acc=[0.88135 0.85335]
30/100: train_loss=[0.35644695 0.43974334], train_acc=[0.8806 0.8545]
32/100: train_loss=[0.34971106 0.4339143 ], train_acc=[0.88185 0.85585]
34/100: train_loss=[0.36150935 0.4335814 ], train_acc=[0.88125 0.8555 ]
36/100: train_loss=[0.34236392 0.42543402], train_acc=[0.88655 0.8581 ]
38/100: train_loss=[0.34705696 0.41699204], train_acc=[0.8846  0.86165]
40/100: train_loss=[0.35661063 0.42247647], train_acc=[0.88115 0.8602 ]
42/100: train_loss=[0.33319852 0.40764174], train_acc=[0.8887 0.8646]
44/100: train_loss=[0.3259032  0.40595782], train_acc=[0.8916  0.86525]
46/100: train_loss=[0.3282118 0.4073529], train_acc=[0.89115 0.86535]
48/100: train_loss=[0.32213992 0.4026449 ], train_acc=[0.8921 0.8651]
50/100: train_loss=[0.3308849  0.41403374], train_acc=[0.8904  0.86255]
52/100: train_loss=[0.3254633 0.4013645], train_acc=[0.8927  0.86835]
54/100: train_loss=[0.31541178 0.38527223], train_acc=[0.89605 0.873  ]
56/100: train_loss=[0.31821004 0.3931637 ], train_acc=[0.89475 0.87135]
58/100: train_loss=[0.31928015 0.38641918], train_acc=[0.89535 0.8732 ]
60/100: train_loss=[0.34932825 0.41535285], train_acc=[0.88385 0.8629 ]
62/100: train_loss=[0.30747372 0.37741178], train_acc=[0.898   0.87535]
64/100: train_loss=[0.3148233  0.37500334], train_acc=[0.89635 0.8765 ]
66/100: train_loss=[0.3080832  0.38377276], train_acc=[0.8993  0.87445]
68/100: train_loss=[0.30830455 0.37667447], train_acc=[0.8981 0.876 ]
70/100: train_loss=[0.30645213 0.38012975], train_acc=[0.8989  0.87605]
72/100: train_loss=[0.30107802 0.36575398], train_acc=[0.9001  0.87875]
74/100: train_loss=[0.29990366 0.370807  ], train_acc=[0.90105 0.8795 ]
76/100: train_loss=[0.30867538 0.37170282], train_acc=[0.89825 0.87915]
78/100: train_loss=[0.30200386 0.37753308], train_acc=[0.9007 0.8762]
80/100: train_loss=[0.29968095 0.36682126], train_acc=[0.9008  0.88085]
82/100: train_loss=[0.29781508 0.36404762], train_acc=[0.9012  0.88025]
84/100: train_loss=[0.29443496 0.36637646], train_acc=[0.90325 0.87895]
86/100: train_loss=[0.29704455 0.36696863], train_acc=[0.90085 0.87945]
88/100: train_loss=[0.30500257 0.37678778], train_acc=[0.8993  0.87665]
90/100: train_loss=[0.29471415 0.35581228], train_acc=[0.90275 0.88325]
92/100: train_loss=[0.2951204  0.36013398], train_acc=[0.9018 0.8824]
94/100: train_loss=[0.3048782  0.36109045], train_acc=[0.9002  0.88065]
96/100: train_loss=[0.2936555  0.35583028], train_acc=[0.90355 0.88465]
98/100: train_loss=[0.30062774 0.36119482], train_acc=[0.9004 0.8816]
100/100: train_loss=[0.296073   0.35942888], train_acc=[0.90195 0.88095]
**** Time taken for mnist_2 = 2586.7360558509827
==>>> total trainning batch number: 469
==>>> total testing batch number: 79
1/100: train_loss=[1.2456845 1.7304599], train_acc=[0.58135 0.39935]
2/100: train_loss=[0.8915889 1.130143 ], train_acc=[0.702   0.61795]
4/100: train_loss=[0.66205084 0.79830116], train_acc=[0.7827  0.73105]
6/100: train_loss=[0.5874111 0.673163 ], train_acc=[0.80825 0.77405]
8/100: train_loss=[0.5365952 0.6215477], train_acc=[0.8256 0.7951]
10/100: train_loss=[0.4717893 0.5856414], train_acc=[0.8427  0.80635]
12/100: train_loss=[0.4698468 0.5868371], train_acc=[0.84295 0.80505]
14/100: train_loss=[0.41765827 0.54126966], train_acc=[0.86335 0.822  ]
16/100: train_loss=[0.4069945  0.54451615], train_acc=[0.86725 0.8192 ]
18/100: train_loss=[0.4004796  0.50267076], train_acc=[0.86705 0.8307 ]
20/100: train_loss=[0.4292366 0.5560698], train_acc=[0.85895 0.8146 ]
22/100: train_loss=[0.37369168 0.47325236], train_acc=[0.87765 0.8381 ]
24/100: train_loss=[0.35457557 0.45685855], train_acc=[0.8831  0.84705]
26/100: train_loss=[0.3667154  0.45106098], train_acc=[0.87775 0.84495]
28/100: train_loss=[0.34933746 0.48848715], train_acc=[0.88485 0.8399 ]
30/100: train_loss=[0.39104012 0.45714107], train_acc=[0.87145 0.8484 ]
32/100: train_loss=[0.33329436 0.42479002], train_acc=[0.8916 0.8565]
34/100: train_loss=[0.3465969 0.4379923], train_acc=[0.8863  0.85305]
36/100: train_loss=[0.33004907 0.41701335], train_acc=[0.8926 0.8595]
38/100: train_loss=[0.32810518 0.418868  ], train_acc=[0.89295 0.85775]
40/100: train_loss=[0.32576054 0.41939667], train_acc=[0.8959 0.8587]
42/100: train_loss=[0.31761223 0.4087355 ], train_acc=[0.89685 0.8623 ]
44/100: train_loss=[0.31203154 0.40927187], train_acc=[0.89895 0.8618 ]
46/100: train_loss=[0.33558285 0.39953053], train_acc=[0.8914  0.86405]
48/100: train_loss=[0.3154494  0.40222093], train_acc=[0.8988  0.86395]
50/100: train_loss=[0.31486177 0.4001679 ], train_acc=[0.8983 0.8655]
52/100: train_loss=[0.31632286 0.39657605], train_acc=[0.8977  0.86615]
54/100: train_loss=[0.30974773 0.39634863], train_acc=[0.89975 0.8676 ]
56/100: train_loss=[0.3120535  0.38480452], train_acc=[0.8995 0.8704]
58/100: train_loss=[0.30439362 0.36959538], train_acc=[0.90115 0.87555]
60/100: train_loss=[0.30172092 0.3891255 ], train_acc=[0.9034  0.86955]
62/100: train_loss=[0.31611252 0.39092776], train_acc=[0.89835 0.8684 ]
64/100: train_loss=[0.29519174 0.3683742 ], train_acc=[0.9042 0.8734]
66/100: train_loss=[0.29768667 0.39744806], train_acc=[0.903   0.86805]
68/100: train_loss=[0.3180774  0.38083848], train_acc=[0.89805 0.8719 ]
70/100: train_loss=[0.2960174  0.36633903], train_acc=[0.9041  0.87795]
72/100: train_loss=[0.29870793 0.37876728], train_acc=[0.90405 0.87405]
74/100: train_loss=[0.29638535 0.3868813 ], train_acc=[0.9042  0.86975]
76/100: train_loss=[0.30313239 0.3665174 ], train_acc=[0.90165 0.87785]
78/100: train_loss=[0.28330067 0.35604703], train_acc=[0.9082  0.88165]
80/100: train_loss=[0.28398052 0.36838403], train_acc=[0.90685 0.8781 ]
82/100: train_loss=[0.30037767 0.35898608], train_acc=[0.90455 0.88105]
84/100: train_loss=[0.2942076 0.3663005], train_acc=[0.90445 0.87775]
86/100: train_loss=[0.2913252 0.3661484], train_acc=[0.9067 0.8789]
88/100: train_loss=[0.28344342 0.35404065], train_acc=[0.90775 0.8813 ]
90/100: train_loss=[0.28519395 0.36047998], train_acc=[0.90855 0.88085]
92/100: train_loss=[0.28895554 0.3566116 ], train_acc=[0.90725 0.8816 ]
94/100: train_loss=[0.28971404 0.3488735 ], train_acc=[0.90665 0.885  ]
96/100: train_loss=[0.28667974 0.3581836 ], train_acc=[0.90955 0.87935]
98/100: train_loss=[0.28066313 0.35408524], train_acc=[0.91005 0.88225]
100/100: train_loss=[0.28206834 0.35121492], train_acc=[0.9088 0.8828]
**** Time taken for mnist_3 = 2481.261859893799
==>>> total trainning batch number: 469
==>>> total testing batch number: 79
1/100: train_loss=[1.2529022 1.3855433], train_acc=[0.58255 0.515  ]
2/100: train_loss=[0.82630575 1.0041819 ], train_acc=[0.72745 0.65855]
4/100: train_loss=[0.61613464 0.7550044 ], train_acc=[0.8022 0.7412]
6/100: train_loss=[0.5484077  0.64093935], train_acc=[0.82345 0.77895]
8/100: train_loss=[0.5001501  0.61345494], train_acc=[0.83755 0.7913 ]
10/100: train_loss=[0.460205 0.563607], train_acc=[0.84995 0.8087 ]
12/100: train_loss=[0.42935562 0.53082365], train_acc=[0.8606 0.8207]
14/100: train_loss=[0.40951538 0.50643575], train_acc=[0.86615 0.8303 ]
16/100: train_loss=[0.3974258  0.53254896], train_acc=[0.87    0.82235]
18/100: train_loss=[0.39152136 0.5029103 ], train_acc=[0.8713 0.8319]
20/100: train_loss=[0.3735525  0.46928716], train_acc=[0.8786 0.8417]
22/100: train_loss=[0.39583772 0.46383634], train_acc=[0.87205 0.8463 ]
24/100: train_loss=[0.36278564 0.44611713], train_acc=[0.88115 0.8485 ]
26/100: train_loss=[0.34816992 0.455371  ], train_acc=[0.88675 0.85025]
28/100: train_loss=[0.372205  0.4520547], train_acc=[0.8805  0.84805]
30/100: train_loss=[0.34201282 0.43192407], train_acc=[0.8871  0.85715]
32/100: train_loss=[0.33308566 0.42088938], train_acc=[0.8902 0.8561]
34/100: train_loss=[0.33629465 0.41548187], train_acc=[0.89085 0.8607 ]
36/100: train_loss=[0.32585913 0.41145635], train_acc=[0.8945 0.86  ]
38/100: train_loss=[0.32347086 0.4009936 ], train_acc=[0.89435 0.8642 ]
40/100: train_loss=[0.31714937 0.40696123], train_acc=[0.8976 0.8637]
42/100: train_loss=[0.32027873 0.39438128], train_acc=[0.8947 0.868 ]
44/100: train_loss=[0.32263234 0.39608717], train_acc=[0.89495 0.86505]
46/100: train_loss=[0.31481218 0.38958335], train_acc=[0.8966 0.8672]
48/100: train_loss=[0.31085584 0.3884611 ], train_acc=[0.89785 0.8689 ]
50/100: train_loss=[0.311511  0.3945603], train_acc=[0.8971  0.86585]
52/100: train_loss=[0.30240032 0.38982445], train_acc=[0.90125 0.86945]
54/100: train_loss=[0.3066642  0.40615562], train_acc=[0.89975 0.86335]
56/100: train_loss=[0.2978182  0.39172956], train_acc=[0.9023 0.8684]
58/100: train_loss=[0.3085613  0.37911606], train_acc=[0.8995 0.8739]
60/100: train_loss=[0.3039455  0.37152544], train_acc=[0.8999 0.8756]
62/100: train_loss=[0.30116835 0.37499034], train_acc=[0.90135 0.8738 ]
64/100: train_loss=[0.29660892 0.38679045], train_acc=[0.90265 0.86785]
66/100: train_loss=[0.29558626 0.37141263], train_acc=[0.9034 0.8755]
68/100: train_loss=[0.2976251  0.37447724], train_acc=[0.9016  0.87405]
70/100: train_loss=[0.33107674 0.39160192], train_acc=[0.89235 0.8686 ]
72/100: train_loss=[0.29314506 0.36143646], train_acc=[0.903   0.87835]
74/100: train_loss=[0.29971096 0.36133307], train_acc=[0.90055 0.87815]
76/100: train_loss=[0.29258066 0.3617007 ], train_acc=[0.9039  0.87785]
78/100: train_loss=[0.29280496 0.37022984], train_acc=[0.90355 0.87565]
80/100: train_loss=[0.29849038 0.36545995], train_acc=[0.90265 0.877  ]
82/100: train_loss=[0.2855303  0.35900277], train_acc=[0.9058 0.8805]
84/100: train_loss=[0.2869138  0.36608413], train_acc=[0.90515 0.87665]
86/100: train_loss=[0.28842363 0.3578095 ], train_acc=[0.90365 0.8804 ]
88/100: train_loss=[0.29242143 0.35652056], train_acc=[0.9029  0.88055]
90/100: train_loss=[0.28605545 0.36600545], train_acc=[0.90575 0.8786 ]
92/100: train_loss=[0.28852576 0.3554916 ], train_acc=[0.9057  0.88135]
94/100: train_loss=[0.29380935 0.35692668], train_acc=[0.90485 0.88035]
96/100: train_loss=[0.29816893 0.35886502], train_acc=[0.9016 0.8803]
98/100: train_loss=[0.28292155 0.3520275 ], train_acc=[0.90815 0.87995]
100/100: train_loss=[0.28598905 0.35847852], train_acc=[0.90665 0.8804 ]
**** Time taken for mnist_4 = 2373.6836290359497
**** Time taken for mnist = 14367.720928430557
==>>> total trainning batch number: 469
==>>> total testing batch number: 79
1/100: train_loss=[1.5473144 1.4712579], train_acc=[0.45135 0.45295]
2/100: train_loss=[1.20686   1.2001418], train_acc=[0.5595 0.5529]
4/100: train_loss=[1.0146195 1.0053526], train_acc=[0.6248 0.6375]
6/100: train_loss=[0.92989606 0.9125577 ], train_acc=[0.65395 0.6582 ]
8/100: train_loss=[0.8458756  0.85058135], train_acc=[0.69165 0.6795 ]
10/100: train_loss=[0.8168683 0.8210581], train_acc=[0.6971  0.70025]
12/100: train_loss=[0.7816884 0.7826487], train_acc=[0.7083 0.7098]
14/100: train_loss=[0.7655973 0.7711855], train_acc=[0.71145 0.7112 ]
16/100: train_loss=[0.74520206 0.7501502 ], train_acc=[0.719   0.72085]
18/100: train_loss=[0.73740536 0.73984635], train_acc=[0.7279  0.73025]
20/100: train_loss=[0.70607585 0.71971464], train_acc=[0.73815 0.7339 ]
22/100: train_loss=[0.6895686  0.71443605], train_acc=[0.745   0.73745]
24/100: train_loss=[0.71205413 0.70910305], train_acc=[0.7311 0.7409]
26/100: train_loss=[0.67611223 0.7021411 ], train_acc=[0.7465  0.73695]
28/100: train_loss=[0.67286956 0.68639064], train_acc=[0.74845 0.7457 ]
30/100: train_loss=[0.6713013  0.69220275], train_acc=[0.7535  0.74535]
32/100: train_loss=[0.657541   0.70369923], train_acc=[0.757  0.7477]
34/100: train_loss=[0.6508436 0.6708099], train_acc=[0.7546  0.75435]
36/100: train_loss=[0.6416676 0.6628894], train_acc=[0.76215 0.75695]
38/100: train_loss=[0.62910104 0.6577511 ], train_acc=[0.7674 0.7569]
40/100: train_loss=[0.6388808 0.6522741], train_acc=[0.76315 0.7629 ]
42/100: train_loss=[0.63028586 0.65317404], train_acc=[0.76495 0.75945]
44/100: train_loss=[0.63015777 0.64246696], train_acc=[0.7696  0.76515]
46/100: train_loss=[0.6362624 0.6421386], train_acc=[0.7696  0.76505]
48/100: train_loss=[0.6068739  0.64207584], train_acc=[0.77695 0.76115]
50/100: train_loss=[0.60142535 0.6376765 ], train_acc=[0.7789  0.76805]
52/100: train_loss=[0.60849875 0.63127804], train_acc=[0.77535 0.76645]
54/100: train_loss=[0.59492844 0.62849957], train_acc=[0.78005 0.7719 ]
56/100: train_loss=[0.6009367 0.6183741], train_acc=[0.77635 0.7766 ]
58/100: train_loss=[0.60782266 0.63543797], train_acc=[0.7771 0.7691]
60/100: train_loss=[0.5891909 0.6163139], train_acc=[0.7828  0.77445]
62/100: train_loss=[0.58293325 0.6183476 ], train_acc=[0.78635 0.77665]
64/100: train_loss=[0.5846602 0.6112253], train_acc=[0.78505 0.77735]
66/100: train_loss=[0.5836705 0.6076948], train_acc=[0.7851 0.7773]
68/100: train_loss=[0.5769096  0.62111944], train_acc=[0.78725 0.7721 ]
70/100: train_loss=[0.5791759 0.6067344], train_acc=[0.78915 0.7795 ]
72/100: train_loss=[0.5823772  0.59941953], train_acc=[0.78895 0.78075]
74/100: train_loss=[0.5673576 0.605441 ], train_acc=[0.7933 0.7769]
76/100: train_loss=[0.56260365 0.5978881 ], train_acc=[0.7947  0.78285]
78/100: train_loss=[0.56780285 0.60071456], train_acc=[0.79325 0.7784 ]
80/100: train_loss=[0.5701952 0.5984442], train_acc=[0.79445 0.77935]
82/100: train_loss=[0.5606923 0.5910858], train_acc=[0.7947 0.7858]
84/100: train_loss=[0.57641435 0.59587216], train_acc=[0.7924  0.78175]
86/100: train_loss=[0.58018893 0.5919474 ], train_acc=[0.78385 0.78805]
88/100: train_loss=[0.5514128 0.6042142], train_acc=[0.79975 0.78325]
90/100: train_loss=[0.5571432 0.5849034], train_acc=[0.79655 0.78685]
92/100: train_loss=[0.560843  0.5876635], train_acc=[0.7944 0.7873]
94/100: train_loss=[0.56932956 0.5879746 ], train_acc=[0.79445 0.78695]
96/100: train_loss=[0.56107175 0.58901316], train_acc=[0.7948 0.7865]
98/100: train_loss=[0.5483817  0.57825005], train_acc=[0.80135 0.786  ]
100/100: train_loss=[0.5516847 0.5844327], train_acc=[0.79995 0.78645]
**** Time taken for fashion_0 = 2375.535003900528
==>>> total trainning batch number: 469
==>>> total testing batch number: 79
1/100: train_loss=[1.3157586 1.3372549], train_acc=[0.5188  0.49995]
2/100: train_loss=[1.0704755 1.0856762], train_acc=[0.60435 0.60035]
4/100: train_loss=[0.91537476 0.9553361 ], train_acc=[0.6599  0.65445]
6/100: train_loss=[0.83062863 0.89550626], train_acc=[0.6846  0.67315]
8/100: train_loss=[0.79999596 0.8461837 ], train_acc=[0.70885 0.682  ]
10/100: train_loss=[0.7767017 0.8347661], train_acc=[0.7062  0.69155]
12/100: train_loss=[0.72335446 0.77794015], train_acc=[0.7308 0.7103]
14/100: train_loss=[0.758021  0.8509104], train_acc=[0.7216  0.68945]
16/100: train_loss=[0.73709035 0.8074571 ], train_acc=[0.7215 0.698 ]
18/100: train_loss=[0.6771255 0.7196304], train_acc=[0.7509  0.73465]
20/100: train_loss=[0.67223465 0.7129157 ], train_acc=[0.74945 0.7364 ]
22/100: train_loss=[0.65139467 0.705943  ], train_acc=[0.7609 0.7398]
24/100: train_loss=[0.6547663 0.7001819], train_acc=[0.7566  0.74045]
26/100: train_loss=[0.6692202 0.6937233], train_acc=[0.7531  0.74635]
28/100: train_loss=[0.6352986  0.67530185], train_acc=[0.7706  0.75245]
30/100: train_loss=[0.64148283 0.6790469 ], train_acc=[0.76545 0.7504 ]
32/100: train_loss=[0.63165855 0.6863726 ], train_acc=[0.76955 0.75145]
34/100: train_loss=[0.6798719 0.6679265], train_acc=[0.74155 0.76015]
36/100: train_loss=[0.6132346  0.67315364], train_acc=[0.77725 0.7539 ]
38/100: train_loss=[0.60531145 0.65345544], train_acc=[0.77895 0.76005]
40/100: train_loss=[0.6131638  0.64707786], train_acc=[0.7722  0.76605]
42/100: train_loss=[0.593989  0.6491182], train_acc=[0.78295 0.76205]
44/100: train_loss=[0.6274653 0.6732617], train_acc=[0.77315 0.75585]
46/100: train_loss=[0.59199834 0.63603276], train_acc=[0.7846 0.7701]
48/100: train_loss=[0.6037793  0.66604847], train_acc=[0.77675 0.7573 ]
50/100: train_loss=[0.58809507 0.638483  ], train_acc=[0.785  0.7661]
52/100: train_loss=[0.58829457 0.6338959 ], train_acc=[0.78445 0.7696 ]
54/100: train_loss=[0.58673626 0.6316008 ], train_acc=[0.7834  0.77045]
56/100: train_loss=[0.5865162 0.6316537], train_acc=[0.7853  0.76945]
58/100: train_loss=[0.5726728 0.6253733], train_acc=[0.7897  0.77165]
60/100: train_loss=[0.57371175 0.62122136], train_acc=[0.7899 0.7759]
62/100: train_loss=[0.5695686  0.61722875], train_acc=[0.79155 0.7754 ]
64/100: train_loss=[0.5737454 0.6075635], train_acc=[0.7884  0.77845]
66/100: train_loss=[0.571432  0.6106426], train_acc=[0.78965 0.7782 ]
68/100: train_loss=[0.5645317 0.6126598], train_acc=[0.7933 0.7777]
70/100: train_loss=[0.57621557 0.6190452 ], train_acc=[0.78975 0.77575]
72/100: train_loss=[0.5608034 0.6026435], train_acc=[0.7937 0.7828]
74/100: train_loss=[0.5697088 0.6059364], train_acc=[0.79135 0.7787 ]
76/100: train_loss=[0.5600368 0.6016244], train_acc=[0.79295 0.78255]
78/100: train_loss=[0.5567875 0.6062212], train_acc=[0.79525 0.7833 ]
80/100: train_loss=[0.55524504 0.60148156], train_acc=[0.7967  0.77985]
82/100: train_loss=[0.5499613 0.6067994], train_acc=[0.7994  0.78035]
84/100: train_loss=[0.5590596 0.6036488], train_acc=[0.79675 0.78075]
86/100: train_loss=[0.5654439 0.5945586], train_acc=[0.7918  0.78385]
88/100: train_loss=[0.5609626  0.58877546], train_acc=[0.7949  0.78715]
90/100: train_loss=[0.5609588 0.591885 ], train_acc=[0.78975 0.7873 ]
92/100: train_loss=[0.5521288 0.5850931], train_acc=[0.7971  0.78865]
94/100: train_loss=[0.5493472 0.5907957], train_acc=[0.8    0.7843]
96/100: train_loss=[0.5507547 0.5868316], train_acc=[0.80025 0.7867 ]
98/100: train_loss=[0.5527231 0.5908341], train_acc=[0.79565 0.78575]
100/100: train_loss=[0.5440953 0.5892282], train_acc=[0.7995 0.7862]
**** Time taken for fashion_1 = 2375.8346943855286
==>>> total trainning batch number: 469
==>>> total testing batch number: 79
1/100: train_loss=[1.154138  1.3509967], train_acc=[0.5641  0.50595]
2/100: train_loss=[1.0005503 1.1001098], train_acc=[0.6156 0.611 ]
4/100: train_loss=[0.8511126 0.8967389], train_acc=[0.6726 0.6721]
6/100: train_loss=[0.78931016 0.8207248 ], train_acc=[0.7017  0.69625]
8/100: train_loss=[0.7413871 0.7845592], train_acc=[0.71825 0.70815]
10/100: train_loss=[0.72137016 0.7531749 ], train_acc=[0.7302 0.7158]
12/100: train_loss=[0.6951813 0.7280336], train_acc=[0.7424 0.7306]
14/100: train_loss=[0.67712396 0.71653354], train_acc=[0.7453 0.7321]
16/100: train_loss=[0.6847183 0.6870372], train_acc=[0.73925 0.74705]
18/100: train_loss=[0.67789215 0.68381065], train_acc=[0.74825 0.74615]
20/100: train_loss=[0.64350754 0.6749216 ], train_acc=[0.7603 0.749 ]
22/100: train_loss=[0.6466143  0.66022915], train_acc=[0.75785 0.7559 ]
24/100: train_loss=[0.64071995 0.66125685], train_acc=[0.7604  0.75925]
26/100: train_loss=[0.63935286 0.664191  ], train_acc=[0.7607 0.7542]
28/100: train_loss=[0.6264192 0.6395556], train_acc=[0.7662  0.76365]
30/100: train_loss=[0.6283555 0.6288665], train_acc=[0.76755 0.77195]
32/100: train_loss=[0.6068266  0.62383693], train_acc=[0.7747 0.7688]
34/100: train_loss=[0.62278885 0.63545036], train_acc=[0.7709 0.7632]
36/100: train_loss=[0.6027257  0.61881226], train_acc=[0.77515 0.77185]
38/100: train_loss=[0.58849925 0.6138654 ], train_acc=[0.7824  0.77655]
40/100: train_loss=[0.5897371  0.60430306], train_acc=[0.78225 0.77975]
42/100: train_loss=[0.5869298 0.6135844], train_acc=[0.7824  0.77825]
44/100: train_loss=[0.5808726 0.6072113], train_acc=[0.7842  0.77455]
46/100: train_loss=[0.57750595 0.60798484], train_acc=[0.7852 0.7786]
48/100: train_loss=[0.57814884 0.5978014 ], train_acc=[0.7853  0.78275]
50/100: train_loss=[0.57189155 0.59291   ], train_acc=[0.7849 0.7814]
52/100: train_loss=[0.5890732 0.6074885], train_acc=[0.78185 0.78415]
54/100: train_loss=[0.5714073 0.59295  ], train_acc=[0.7894  0.78525]
56/100: train_loss=[0.56308526 0.6044033 ], train_acc=[0.79285 0.7805 ]
58/100: train_loss=[0.5659367  0.58647394], train_acc=[0.7922  0.78795]
60/100: train_loss=[0.5675578 0.5953028], train_acc=[0.7933 0.7802]
62/100: train_loss=[0.5621044 0.5967748], train_acc=[0.79215 0.78335]
64/100: train_loss=[0.56725025 0.58702016], train_acc=[0.78795 0.78375]
66/100: train_loss=[0.5541819  0.58754987], train_acc=[0.7941  0.78535]
68/100: train_loss=[0.57473063 0.59501314], train_acc=[0.7852 0.7814]
70/100: train_loss=[0.5605819  0.59681046], train_acc=[0.7932  0.78415]
72/100: train_loss=[0.5793454 0.5903304], train_acc=[0.7852 0.7865]
74/100: train_loss=[0.545847   0.57178754], train_acc=[0.79745 0.79085]
76/100: train_loss=[0.54515785 0.5803677 ], train_acc=[0.8004  0.78755]
78/100: train_loss=[0.5669291 0.5774665], train_acc=[0.78935 0.79   ]
80/100: train_loss=[0.54431516 0.57168037], train_acc=[0.79995 0.78895]
82/100: train_loss=[0.5585284  0.56925476], train_acc=[0.7918 0.7897]
84/100: train_loss=[0.55133027 0.5700683 ], train_acc=[0.7965 0.7911]
86/100: train_loss=[0.5578341 0.5841818], train_acc=[0.7926  0.78915]
88/100: train_loss=[0.5436663 0.5732878], train_acc=[0.79915 0.79335]
90/100: train_loss=[0.54138786 0.570345  ], train_acc=[0.8004 0.7904]
92/100: train_loss=[0.543785  0.5641189], train_acc=[0.7996  0.79405]
94/100: train_loss=[0.5308903  0.56711507], train_acc=[0.8036 0.7928]
96/100: train_loss=[0.53687483 0.5667966 ], train_acc=[0.7997 0.7901]
98/100: train_loss=[0.5353376 0.5616621], train_acc=[0.80455 0.79425]
100/100: train_loss=[0.532638   0.56111825], train_acc=[0.80485 0.79535]
**** Time taken for fashion_2 = 2377.9614396095276
==>>> total trainning batch number: 469
==>>> total testing batch number: 79
1/100: train_loss=[1.1593245 1.2390456], train_acc=[0.56115 0.54975]
2/100: train_loss=[1.0368612 1.0954709], train_acc=[0.6141  0.58995]
4/100: train_loss=[0.8438471 0.8856808], train_acc=[0.67885 0.67345]
6/100: train_loss=[0.7818631 0.8087908], train_acc=[0.70775 0.70425]
8/100: train_loss=[0.7518656  0.78401726], train_acc=[0.7131  0.71315]
10/100: train_loss=[0.73944443 0.7465474 ], train_acc=[0.7226 0.7258]
12/100: train_loss=[0.73332864 0.73737335], train_acc=[0.72385 0.7249 ]
14/100: train_loss=[0.6945921 0.7078814], train_acc=[0.745  0.7454]
16/100: train_loss=[0.6833114 0.7195554], train_acc=[0.74555 0.73815]
18/100: train_loss=[0.6858355 0.7312628], train_acc=[0.74285 0.72035]
20/100: train_loss=[0.65546304 0.6780844 ], train_acc=[0.7529 0.7523]
22/100: train_loss=[0.6580488  0.67149043], train_acc=[0.7558  0.75255]
24/100: train_loss=[0.6401497 0.6523984], train_acc=[0.7643  0.76235]
26/100: train_loss=[0.65298384 0.6517008 ], train_acc=[0.75915 0.76445]
28/100: train_loss=[0.6364404 0.6680259], train_acc=[0.7648  0.75495]
30/100: train_loss=[0.6242874  0.64260256], train_acc=[0.7669  0.76665]
32/100: train_loss=[0.61500925 0.66333246], train_acc=[0.7717 0.7593]
34/100: train_loss=[0.6266861 0.6371271], train_acc=[0.76825 0.76735]
36/100: train_loss=[0.6010759  0.62548155], train_acc=[0.7782  0.77475]
38/100: train_loss=[0.65129083 0.62087005], train_acc=[0.75275 0.77465]
40/100: train_loss=[0.59267956 0.6173471 ], train_acc=[0.7798  0.77645]
42/100: train_loss=[0.5949868  0.60701364], train_acc=[0.7793 0.7807]
44/100: train_loss=[0.5964726 0.6205265], train_acc=[0.77795 0.7756 ]
46/100: train_loss=[0.5839962  0.62076724], train_acc=[0.7826  0.77535]
48/100: train_loss=[0.58121306 0.60074675], train_acc=[0.78645 0.78065]
50/100: train_loss=[0.5796516 0.5992665], train_acc=[0.78605 0.7828 ]
52/100: train_loss=[0.5744131  0.61718416], train_acc=[0.7879 0.7755]
54/100: train_loss=[0.61264545 0.5992653 ], train_acc=[0.7733  0.78385]
56/100: train_loss=[0.58039844 0.6032425 ], train_acc=[0.7861 0.7792]
58/100: train_loss=[0.5651299 0.5962566], train_acc=[0.7915  0.78385]
60/100: train_loss=[0.57360554 0.5993051 ], train_acc=[0.78795 0.78145]
62/100: train_loss=[0.58600974 0.57941204], train_acc=[0.78295 0.79125]
64/100: train_loss=[0.5685435 0.5876   ], train_acc=[0.79135 0.7884 ]
66/100: train_loss=[0.5813194 0.5894918], train_acc=[0.78615 0.78855]
68/100: train_loss=[0.556619  0.5785175], train_acc=[0.79635 0.789  ]
70/100: train_loss=[0.5537142 0.5865862], train_acc=[0.7963 0.785 ]
72/100: train_loss=[0.5585381 0.5787553], train_acc=[0.79315 0.78955]
74/100: train_loss=[0.55387473 0.5764006 ], train_acc=[0.7977 0.7925]
76/100: train_loss=[0.55552614 0.600099  ], train_acc=[0.79455 0.78485]
78/100: train_loss=[0.5602914 0.5797919], train_acc=[0.79   0.7898]
80/100: train_loss=[0.55152357 0.5870246 ], train_acc=[0.79705 0.78485]
82/100: train_loss=[0.5513978 0.5700395], train_acc=[0.79775 0.79385]
84/100: train_loss=[0.55009913 0.5748165 ], train_acc=[0.79825 0.79205]
86/100: train_loss=[0.54770744 0.569018  ], train_acc=[0.7956 0.796 ]
88/100: train_loss=[0.559967   0.58770084], train_acc=[0.7928 0.7896]
90/100: train_loss=[0.53842694 0.56502235], train_acc=[0.80085 0.7974 ]
92/100: train_loss=[0.538799   0.56120443], train_acc=[0.80225 0.799  ]
94/100: train_loss=[0.54139656 0.56580865], train_acc=[0.8003  0.79825]
96/100: train_loss=[0.5434959  0.55901927], train_acc=[0.7964  0.79575]
98/100: train_loss=[0.5427908 0.5699604], train_acc=[0.7994 0.7938]
100/100: train_loss=[0.53355044 0.57873553], train_acc=[0.8022 0.7935]
**** Time taken for fashion_3 = 2379.436341047287
==>>> total trainning batch number: 469
==>>> total testing batch number: 79
1/100: train_loss=[1.1786151 1.2010654], train_acc=[0.55715 0.56285]
2/100: train_loss=[0.9887933 1.0281309], train_acc=[0.63335 0.62705]
4/100: train_loss=[0.84064204 0.84565854], train_acc=[0.6854  0.69125]
6/100: train_loss=[0.81031847 0.77644354], train_acc=[0.69595 0.7144 ]
8/100: train_loss=[0.7320327 0.7365185], train_acc=[0.726   0.72515]
10/100: train_loss=[0.7120347 0.7048249], train_acc=[0.7317 0.7422]
12/100: train_loss=[0.7048125  0.70638245], train_acc=[0.73625 0.73495]
14/100: train_loss=[0.69259965 0.6707916 ], train_acc=[0.7386 0.755 ]
16/100: train_loss=[0.65462714 0.6600548 ], train_acc=[0.7546 0.7595]
18/100: train_loss=[0.64651203 0.6375251 ], train_acc=[0.75905 0.7659 ]
20/100: train_loss=[0.62630355 0.6361661 ], train_acc=[0.7687  0.76305]
22/100: train_loss=[0.6195846 0.6434438], train_acc=[0.7685  0.76585]
24/100: train_loss=[0.6237587 0.619511 ], train_acc=[0.76895 0.77395]
26/100: train_loss=[0.6014973 0.6086465], train_acc=[0.77675 0.78105]
28/100: train_loss=[0.609856  0.6125611], train_acc=[0.7722  0.77925]
30/100: train_loss=[0.59370714 0.60297483], train_acc=[0.7778  0.78055]
32/100: train_loss=[0.60681474 0.5958417 ], train_acc=[0.7673 0.784 ]
34/100: train_loss=[0.5785662  0.59766823], train_acc=[0.78495 0.7852 ]
36/100: train_loss=[0.5782826 0.5862271], train_acc=[0.78735 0.78525]
38/100: train_loss=[0.5685784 0.5818252], train_acc=[0.7895  0.78955]
40/100: train_loss=[0.5655288 0.5799429], train_acc=[0.78975 0.7909 ]
42/100: train_loss=[0.56588775 0.5768672 ], train_acc=[0.78795 0.79165]
44/100: train_loss=[0.5540125 0.5743245], train_acc=[0.7951 0.7927]
46/100: train_loss=[0.56948596 0.57194227], train_acc=[0.7886  0.79605]
48/100: train_loss=[0.55509174 0.5628813 ], train_acc=[0.7947  0.79355]
50/100: train_loss=[0.56748426 0.5666276 ], train_acc=[0.79165 0.79425]
52/100: train_loss=[0.54598993 0.5708641 ], train_acc=[0.7987 0.7904]
54/100: train_loss=[0.5565782 0.5772995], train_acc=[0.79095 0.79285]
56/100: train_loss=[0.5474337  0.55810505], train_acc=[0.7952  0.79715]
58/100: train_loss=[0.5384129  0.56167644], train_acc=[0.7975 0.795 ]
60/100: train_loss=[0.5360249 0.562768 ], train_acc=[0.7987  0.79675]
62/100: train_loss=[0.54018384 0.5744898 ], train_acc=[0.79895 0.78885]
64/100: train_loss=[0.5404559 0.5488581], train_acc=[0.7978 0.8009]
66/100: train_loss=[0.53695685 0.55813646], train_acc=[0.8031 0.794 ]
68/100: train_loss=[0.5395619 0.5620712], train_acc=[0.79965 0.7953 ]
70/100: train_loss=[0.54154605 0.54496884], train_acc=[0.79855 0.80435]
72/100: train_loss=[0.53860605 0.55516   ], train_acc=[0.79995 0.79675]
74/100: train_loss=[0.5235382  0.54640275], train_acc=[0.8047 0.8019]
76/100: train_loss=[0.5491068 0.555984 ], train_acc=[0.79545 0.7958 ]
78/100: train_loss=[0.5251797  0.54890543], train_acc=[0.805  0.7987]
80/100: train_loss=[0.5392407  0.56301314], train_acc=[0.7972 0.7983]
82/100: train_loss=[0.5297098  0.55063385], train_acc=[0.8018 0.8016]
84/100: train_loss=[0.518871 0.552527], train_acc=[0.8096  0.79975]
86/100: train_loss=[0.5174843 0.5368095], train_acc=[0.80775 0.8061 ]
88/100: train_loss=[0.52477866 0.53269225], train_acc=[0.80655 0.80755]
90/100: train_loss=[0.5134909 0.5401653], train_acc=[0.81065 0.8039 ]
92/100: train_loss=[0.518096  0.5448986], train_acc=[0.80875 0.7992 ]
94/100: train_loss=[0.5206699 0.5454486], train_acc=[0.8099  0.80445]
96/100: train_loss=[0.5114351  0.55947167], train_acc=[0.81165 0.796  ]
98/100: train_loss=[0.522654  0.5417267], train_acc=[0.80515 0.808  ]
100/100: train_loss=[0.51357263 0.5365934 ], train_acc=[0.80965 0.80625]
**** Time taken for fashion_4 = 2378.993278026581
**** Time taken for fashion = 11887.837831020355
==>>> total trainning batch number: 469
==>>> total testing batch number: 79
1/100: train_loss=[1.6469045 1.2175773], train_acc=[0.43105 0.56765]
2/100: train_loss=[1.188734  1.0186944], train_acc=[0.5928  0.62925]
4/100: train_loss=[0.8709372 0.8687507], train_acc=[0.7057  0.68785]
6/100: train_loss=[0.72538143 0.78751373], train_acc=[0.7609 0.7102]
8/100: train_loss=[0.64102346 0.7432424 ], train_acc=[0.7872 0.7255]
10/100: train_loss=[0.58149964 0.70934606], train_acc=[0.8083  0.73825]
12/100: train_loss=[0.5250406 0.6775954], train_acc=[0.8284  0.74935]
14/100: train_loss=[0.4879109  0.66018534], train_acc=[0.84225 0.7562 ]
16/100: train_loss=[0.45894745 0.6455994 ], train_acc=[0.852  0.7621]
18/100: train_loss=[0.45356524 0.64866966], train_acc=[0.85215 0.7607 ]
20/100: train_loss=[0.41813722 0.6354901 ], train_acc=[0.8659  0.75935]
22/100: train_loss=[0.41453853 0.60951996], train_acc=[0.8673 0.7757]
24/100: train_loss=[0.40576676 0.6071161 ], train_acc=[0.8657  0.77545]
26/100: train_loss=[0.40093967 0.592484  ], train_acc=[0.8706 0.7805]
28/100: train_loss=[0.37058926 0.59570956], train_acc=[0.8833  0.78265]
30/100: train_loss=[0.38089606 0.58469886], train_acc=[0.87775 0.7826 ]
32/100: train_loss=[0.358099  0.5731504], train_acc=[0.8853 0.7905]
34/100: train_loss=[0.35507208 0.6189596 ], train_acc=[0.886   0.78225]
36/100: train_loss=[0.34132096 0.5620443 ], train_acc=[0.89045 0.7968 ]
38/100: train_loss=[0.33609888 0.55828077], train_acc=[0.8933 0.7962]
40/100: train_loss=[0.3450825 0.5584323], train_acc=[0.8875  0.79585]
42/100: train_loss=[0.3317633 0.5685554], train_acc=[0.8934  0.79075]
44/100: train_loss=[0.33397126 0.55274093], train_acc=[0.892   0.79885]
46/100: train_loss=[0.32151157 0.54779184], train_acc=[0.8959 0.7988]
48/100: train_loss=[0.31494692 0.5488003 ], train_acc=[0.89825 0.7966 ]
50/100: train_loss=[0.30993494 0.5522455 ], train_acc=[0.90025 0.79565]
52/100: train_loss=[0.30561444 0.5406992 ], train_acc=[0.9026  0.80195]
54/100: train_loss=[0.30378327 0.53211206], train_acc=[0.9024  0.80705]
56/100: train_loss=[0.29547307 0.52884465], train_acc=[0.9039  0.80725]
58/100: train_loss=[0.30234346 0.55290663], train_acc=[0.9027  0.79875]
60/100: train_loss=[0.29509935 0.53405476], train_acc=[0.90515 0.8041 ]
62/100: train_loss=[0.29344597 0.55167544], train_acc=[0.90465 0.797  ]
64/100: train_loss=[0.305515  0.5253424], train_acc=[0.9017 0.8041]
66/100: train_loss=[0.2898493 0.5374184], train_acc=[0.90705 0.80075]
68/100: train_loss=[0.29382607 0.5235861 ], train_acc=[0.9079  0.81095]
70/100: train_loss=[0.2830256 0.5180993], train_acc=[0.90775 0.80935]
72/100: train_loss=[0.28076836 0.5148862 ], train_acc=[0.9098  0.81175]
74/100: train_loss=[0.28153893 0.5171928 ], train_acc=[0.9107 0.8107]
76/100: train_loss=[0.29463878 0.5219801 ], train_acc=[0.9059 0.8084]
78/100: train_loss=[0.2803315  0.50948143], train_acc=[0.9111 0.8162]
80/100: train_loss=[0.28060699 0.50385636], train_acc=[0.90975 0.81625]
82/100: train_loss=[0.27595848 0.5157717 ], train_acc=[0.90965 0.8139 ]
84/100: train_loss=[0.277069   0.49780825], train_acc=[0.91085 0.8209 ]
86/100: train_loss=[0.28433588 0.50249314], train_acc=[0.9078 0.8151]
88/100: train_loss=[0.2757705 0.5047311], train_acc=[0.90935 0.81565]
90/100: train_loss=[0.29294336 0.50598174], train_acc=[0.90625 0.8184 ]
92/100: train_loss=[0.26994762 0.50433326], train_acc=[0.9113 0.8141]
94/100: train_loss=[0.2718848 0.4987528], train_acc=[0.9121 0.8186]
96/100: train_loss=[0.28151587 0.50417984], train_acc=[0.90835 0.81795]
98/100: train_loss=[0.26888385 0.4961379 ], train_acc=[0.91455 0.8189 ]
100/100: train_loss=[0.27707276 0.5046376 ], train_acc=[0.9115  0.81625]
**** Time taken for fashion_and_mnist_0 = 2378.547016620636
==>>> total trainning batch number: 469
==>>> total testing batch number: 79
1/100: train_loss=[1.3645269 1.2737451], train_acc=[0.5326  0.54625]
2/100: train_loss=[1.0299282 0.9658533], train_acc=[0.65145 0.6554 ]
4/100: train_loss=[0.7390311 0.8176031], train_acc=[0.75465 0.7043 ]
6/100: train_loss=[0.62600386 0.77529144], train_acc=[0.7925 0.72  ]
8/100: train_loss=[0.56552655 0.71190816], train_acc=[0.8151  0.74075]
10/100: train_loss=[0.5214243 0.6915521], train_acc=[0.82905 0.74485]
12/100: train_loss=[0.50362074 0.6658434 ], train_acc=[0.83395 0.75655]
14/100: train_loss=[0.44771412 0.64556295], train_acc=[0.85345 0.75855]
16/100: train_loss=[0.44581237 0.6310403 ], train_acc=[0.85345 0.76585]
18/100: train_loss=[0.41715324 0.6236092 ], train_acc=[0.86295 0.76795]
20/100: train_loss=[0.45320308 0.6138776 ], train_acc=[0.8505 0.7724]
22/100: train_loss=[0.39214134 0.61619157], train_acc=[0.8703 0.7723]
24/100: train_loss=[0.38753673 0.6087217 ], train_acc=[0.8723 0.7734]
26/100: train_loss=[0.36182237 0.59369093], train_acc=[0.8841 0.7806]
28/100: train_loss=[0.35383245 0.59059626], train_acc=[0.8829  0.78055]
30/100: train_loss=[0.3391816 0.5728581], train_acc=[0.88905 0.792  ]
32/100: train_loss=[0.36752826 0.5726018 ], train_acc=[0.8811  0.78785]
34/100: train_loss=[0.33653358 0.59417087], train_acc=[0.891   0.77945]
36/100: train_loss=[0.32224748 0.5583765 ], train_acc=[0.89695 0.79225]
38/100: train_loss=[0.32819492 0.55380034], train_acc=[0.89415 0.7931 ]
40/100: train_loss=[0.31870678 0.56038153], train_acc=[0.8983  0.79215]
42/100: train_loss=[0.31025758 0.54885274], train_acc=[0.90055 0.79575]
44/100: train_loss=[0.36169446 0.5685361 ], train_acc=[0.8825  0.78855]
46/100: train_loss=[0.3176286  0.54925853], train_acc=[0.89605 0.79625]
48/100: train_loss=[0.30607814 0.54497623], train_acc=[0.90295 0.79835]
50/100: train_loss=[0.30389488 0.55493176], train_acc=[0.90105 0.7947 ]
52/100: train_loss=[0.29038173 0.53859293], train_acc=[0.90795 0.8007 ]
54/100: train_loss=[0.3071092 0.5455928], train_acc=[0.8986 0.7985]
56/100: train_loss=[0.32836366 0.54851705], train_acc=[0.89535 0.796  ]
58/100: train_loss=[0.3053934  0.52221936], train_acc=[0.90035 0.80645]
60/100: train_loss=[0.29640242 0.53067833], train_acc=[0.9054 0.8058]
62/100: train_loss=[0.28962845 0.5160624 ], train_acc=[0.90575 0.8096 ]
64/100: train_loss=[0.30539268 0.51769924], train_acc=[0.9025 0.8102]
66/100: train_loss=[0.28838894 0.5385292 ], train_acc=[0.9087 0.7954]
68/100: train_loss=[0.26843977 0.51196355], train_acc=[0.91615 0.8092 ]
70/100: train_loss=[0.27296773 0.5222145 ], train_acc=[0.91405 0.80925]
72/100: train_loss=[0.2708448  0.51262265], train_acc=[0.91435 0.81165]
74/100: train_loss=[0.2707453 0.5182334], train_acc=[0.91375 0.80995]
76/100: train_loss=[0.26969132 0.508548  ], train_acc=[0.9134 0.8119]
78/100: train_loss=[0.26580265 0.50524265], train_acc=[0.9161  0.81175]
80/100: train_loss=[0.26968572 0.50494725], train_acc=[0.9136  0.81185]
82/100: train_loss=[0.26209152 0.5058224 ], train_acc=[0.91605 0.81135]
84/100: train_loss=[0.26396152 0.50924003], train_acc=[0.91725 0.814  ]
86/100: train_loss=[0.28307325 0.4940991 ], train_acc=[0.9112 0.8163]
88/100: train_loss=[0.26801875 0.49997163], train_acc=[0.9163 0.816 ]
90/100: train_loss=[0.2537216 0.5019156], train_acc=[0.9208 0.814 ]
92/100: train_loss=[0.25890154 0.50153166], train_acc=[0.9182 0.8141]
94/100: train_loss=[0.25891656 0.49363676], train_acc=[0.91835 0.819  ]
96/100: train_loss=[0.2562464  0.49215025], train_acc=[0.9174  0.81775]
98/100: train_loss=[0.26341778 0.4905234 ], train_acc=[0.9177 0.8197]
100/100: train_loss=[0.26155612 0.4902821 ], train_acc=[0.91655 0.8198 ]
**** Time taken for fashion_and_mnist_1 = 2236.172754764557
==>>> total trainning batch number: 469
==>>> total testing batch number: 79
1/100: train_loss=[1.4756057 1.1893129], train_acc=[0.4954 0.5676]
2/100: train_loss=[1.1034973 0.9477386], train_acc=[0.63575 0.65545]
4/100: train_loss=[0.9076355 0.8625653], train_acc=[0.6945  0.67975]
6/100: train_loss=[0.6878811  0.75548124], train_acc=[0.77055 0.722  ]
8/100: train_loss=[0.6218707  0.70754546], train_acc=[0.79525 0.742  ]
10/100: train_loss=[0.5464772  0.68553114], train_acc=[0.8194 0.7521]
12/100: train_loss=[0.5734288 0.6644554], train_acc=[0.80895 0.7579 ]
14/100: train_loss=[0.45939347 0.6421333 ], train_acc=[0.85415 0.7656 ]
16/100: train_loss=[0.4810387  0.65650934], train_acc=[0.84535 0.75935]
18/100: train_loss=[0.43039554 0.6290903 ], train_acc=[0.8604 0.7683]
20/100: train_loss=[0.41003627 0.6136866 ], train_acc=[0.86695 0.77225]
22/100: train_loss=[0.38480422 0.60944575], train_acc=[0.8774 0.7791]
24/100: train_loss=[0.40455887 0.6126434 ], train_acc=[0.86925 0.7761 ]
26/100: train_loss=[0.3678525 0.5990308], train_acc=[0.88225 0.7815 ]
28/100: train_loss=[0.39787674 0.5937856 ], train_acc=[0.8698  0.78105]
30/100: train_loss=[0.35325658 0.5854196 ], train_acc=[0.8856  0.78135]
32/100: train_loss=[0.34482273 0.61191076], train_acc=[0.88885 0.76895]
34/100: train_loss=[0.347915   0.57275933], train_acc=[0.88735 0.7897 ]
36/100: train_loss=[0.33569264 0.5675278 ], train_acc=[0.8905 0.7903]
38/100: train_loss=[0.34083828 0.55797666], train_acc=[0.89065 0.7951 ]
40/100: train_loss=[0.32899842 0.56289744], train_acc=[0.89515 0.7907 ]
42/100: train_loss=[0.3512039  0.55802345], train_acc=[0.8857  0.79655]
44/100: train_loss=[0.3317997  0.54713374], train_acc=[0.8926  0.79945]
46/100: train_loss=[0.30627665 0.54783565], train_acc=[0.90195 0.79955]
48/100: train_loss=[0.31868246 0.54057693], train_acc=[0.89605 0.8042 ]
50/100: train_loss=[0.30827406 0.54168254], train_acc=[0.90015 0.8005 ]
52/100: train_loss=[0.30389035 0.55729085], train_acc=[0.9028 0.7961]
54/100: train_loss=[0.29899684 0.53213423], train_acc=[0.9039  0.80475]
56/100: train_loss=[0.30341834 0.5323206 ], train_acc=[0.9033  0.80145]
58/100: train_loss=[0.30874765 0.5290997 ], train_acc=[0.90115 0.8055 ]
60/100: train_loss=[0.2921805 0.5375917], train_acc=[0.9049  0.79985]
62/100: train_loss=[0.28482133 0.5210031 ], train_acc=[0.90825 0.80715]
64/100: train_loss=[0.3046654 0.5525136], train_acc=[0.9046 0.7979]
66/100: train_loss=[0.2793734 0.5222322], train_acc=[0.9122 0.808 ]
68/100: train_loss=[0.28006858 0.5255104 ], train_acc=[0.91005 0.80395]
70/100: train_loss=[0.288338   0.51885736], train_acc=[0.90865 0.8053 ]
72/100: train_loss=[0.27472278 0.5137412 ], train_acc=[0.9136  0.81095]
74/100: train_loss=[0.2771453  0.52587473], train_acc=[0.91115 0.80655]
76/100: train_loss=[0.27654788 0.5217979 ], train_acc=[0.91345 0.8048 ]
78/100: train_loss=[0.2674113 0.5061279], train_acc=[0.916   0.81245]
80/100: train_loss=[0.2731998  0.50573575], train_acc=[0.91445 0.8135 ]
82/100: train_loss=[0.2790823  0.50679165], train_acc=[0.91145 0.8127 ]
84/100: train_loss=[0.27354586 0.5061108 ], train_acc=[0.9119 0.8117]
86/100: train_loss=[0.257477   0.50678426], train_acc=[0.91875 0.8096 ]
88/100: train_loss=[0.26320505 0.5054924 ], train_acc=[0.91785 0.8139 ]
90/100: train_loss=[0.2749779  0.50117433], train_acc=[0.9125 0.8123]
92/100: train_loss=[0.25667888 0.49085605], train_acc=[0.9193  0.81855]
94/100: train_loss=[0.27578333 0.50532144], train_acc=[0.9123 0.812 ]
96/100: train_loss=[0.2624124  0.50206494], train_acc=[0.91645 0.814  ]
98/100: train_loss=[0.25992626 0.4962904 ], train_acc=[0.91665 0.81485]
100/100: train_loss=[0.26559338 0.4864424 ], train_acc=[0.91475 0.8195 ]
**** Time taken for fashion_and_mnist_2 = 2092.2410278320312
==>>> total trainning batch number: 469
==>>> total testing batch number: 79
1/100: train_loss=[1.2553644 1.0056268], train_acc=[0.5721 0.6359]
2/100: train_loss=[0.91425705 0.88960874], train_acc=[0.697  0.6694]
4/100: train_loss=[0.67661256 0.7509156 ], train_acc=[0.77945 0.7237 ]
6/100: train_loss=[0.5280751 0.7055528], train_acc=[0.826  0.7424]
8/100: train_loss=[0.47742382 0.6835912 ], train_acc=[0.8436 0.7415]
10/100: train_loss=[0.42684504 0.6532071 ], train_acc=[0.86235 0.7606 ]
12/100: train_loss=[0.4303562  0.61771053], train_acc=[0.8604 0.7688]
14/100: train_loss=[0.3922154  0.62780833], train_acc=[0.87335 0.76275]
16/100: train_loss=[0.3575929 0.5854741], train_acc=[0.8852 0.7818]
18/100: train_loss=[0.37054607 0.5856433 ], train_acc=[0.88055 0.78265]
20/100: train_loss=[0.33266163 0.57568586], train_acc=[0.89435 0.7866 ]
22/100: train_loss=[0.31548956 0.5545299 ], train_acc=[0.8995  0.79185]
24/100: train_loss=[0.311868  0.5543614], train_acc=[0.9006  0.79175]
26/100: train_loss=[0.3259526  0.54309016], train_acc=[0.8955 0.7966]
28/100: train_loss=[0.29162267 0.5538926 ], train_acc=[0.90775 0.7932 ]
30/100: train_loss=[0.30922517 0.5353823 ], train_acc=[0.9013  0.80105]
32/100: train_loss=[0.28392562 0.53449017], train_acc=[0.90865 0.80075]
34/100: train_loss=[0.29578748 0.54053605], train_acc=[0.90635 0.7967 ]
36/100: train_loss=[0.30440417 0.54012406], train_acc=[0.9016 0.7998]
38/100: train_loss=[0.2751242 0.5177232], train_acc=[0.9137  0.80895]
40/100: train_loss=[0.2775678  0.52706856], train_acc=[0.91125 0.80065]
42/100: train_loss=[0.26923287 0.5132371 ], train_acc=[0.9142 0.8089]
44/100: train_loss=[0.2601689 0.5383669], train_acc=[0.916   0.79625]
46/100: train_loss=[0.25676125 0.5050198 ], train_acc=[0.91965 0.80885]
48/100: train_loss=[0.2637502  0.52289474], train_acc=[0.91545 0.80235]
50/100: train_loss=[0.2657394 0.5234592], train_acc=[0.9137  0.80495]
52/100: train_loss=[0.2681227  0.49836853], train_acc=[0.9131 0.8125]
54/100: train_loss=[0.24441776 0.49599376], train_acc=[0.92175 0.81505]
56/100: train_loss=[0.24645297 0.505111  ], train_acc=[0.9206 0.813 ]
58/100: train_loss=[0.25171006 0.50468254], train_acc=[0.91925 0.80965]
60/100: train_loss=[0.25939256 0.502003  ], train_acc=[0.91505 0.8138 ]
62/100: train_loss=[0.24590647 0.53174186], train_acc=[0.92345 0.8021 ]
64/100: train_loss=[0.23915228 0.4940755 ], train_acc=[0.92355 0.8134 ]
66/100: train_loss=[0.24924393 0.49025303], train_acc=[0.9202 0.8159]
68/100: train_loss=[0.24003616 0.48836306], train_acc=[0.92215 0.8173 ]
70/100: train_loss=[0.23402022 0.48690343], train_acc=[0.9256 0.8191]
72/100: train_loss=[0.23739156 0.49171844], train_acc=[0.9223  0.81475]
74/100: train_loss=[0.254015  0.5066923], train_acc=[0.916   0.81495]
76/100: train_loss=[0.23153518 0.4766417 ], train_acc=[0.92605 0.8213 ]
78/100: train_loss=[0.2299195  0.48172265], train_acc=[0.926   0.82255]
80/100: train_loss=[0.2367663 0.4822368], train_acc=[0.92315 0.81985]
82/100: train_loss=[0.2391357 0.478935 ], train_acc=[0.92315 0.8217 ]
84/100: train_loss=[0.23409593 0.5048168 ], train_acc=[0.92605 0.8104 ]
86/100: train_loss=[0.24827443 0.5003101 ], train_acc=[0.9199  0.81585]
88/100: train_loss=[0.2328163 0.4774102], train_acc=[0.92575 0.8228 ]
90/100: train_loss=[0.24170558 0.47630906], train_acc=[0.92255 0.8201 ]
92/100: train_loss=[0.23149268 0.48366413], train_acc=[0.92495 0.8168 ]
94/100: train_loss=[0.23598024 0.48044163], train_acc=[0.925  0.8197]
96/100: train_loss=[0.22348982 0.49659663], train_acc=[0.92785 0.8128 ]
98/100: train_loss=[0.2251193  0.48922846], train_acc=[0.9278  0.81535]
100/100: train_loss=[0.2277169 0.4759913], train_acc=[0.9252 0.8216]
**** Time taken for fashion_and_mnist_3 = 2093.7455978393555
==>>> total trainning batch number: 469
==>>> total testing batch number: 79
1/100: train_loss=[1.6337539 1.584288 ], train_acc=[0.43185 0.44855]
2/100: train_loss=[1.1011932 0.953598 ], train_acc=[0.6277 0.6474]
4/100: train_loss=[0.78495663 0.7939931 ], train_acc=[0.74305 0.7115 ]
6/100: train_loss=[0.6758194 0.8174371], train_acc=[0.7774 0.6987]
8/100: train_loss=[0.5769586  0.72109246], train_acc=[0.8139  0.73095]
10/100: train_loss=[0.53622556 0.6756435 ], train_acc=[0.8275 0.7533]
12/100: train_loss=[0.5666758  0.68270767], train_acc=[0.8169 0.7463]
14/100: train_loss=[0.45262486 0.6549667 ], train_acc=[0.85755 0.75605]
16/100: train_loss=[0.4550932 0.64233  ], train_acc=[0.8521  0.75885]
18/100: train_loss=[0.41735736 0.6111849 ], train_acc=[0.86575 0.7759 ]
20/100: train_loss=[0.43317893 0.6277402 ], train_acc=[0.85865 0.76955]
22/100: train_loss=[0.38675067 0.60388905], train_acc=[0.87505 0.7765 ]
24/100: train_loss=[0.36950788 0.5948271 ], train_acc=[0.8822 0.7801]
26/100: train_loss=[0.3702521  0.57221097], train_acc=[0.88085 0.7881 ]
28/100: train_loss=[0.35405314 0.57903767], train_acc=[0.8858 0.7852]
30/100: train_loss=[0.34210396 0.5758917 ], train_acc=[0.8922  0.78865]
32/100: train_loss=[0.34930286 0.5704029 ], train_acc=[0.88755 0.7879 ]
34/100: train_loss=[0.30986798 0.5847551 ], train_acc=[0.90055 0.7857 ]
36/100: train_loss=[0.3167599 0.5500541], train_acc=[0.8978  0.79445]
38/100: train_loss=[0.30026457 0.55563504], train_acc=[0.9036 0.7946]
40/100: train_loss=[0.3043511 0.5582323], train_acc=[0.9032  0.78985]
42/100: train_loss=[0.3210088  0.53586215], train_acc=[0.8952 0.8027]
44/100: train_loss=[0.29157582 0.5789815 ], train_acc=[0.9073 0.7853]
46/100: train_loss=[0.29211882 0.5472505 ], train_acc=[0.9067  0.79375]
48/100: train_loss=[0.28478786 0.53921026], train_acc=[0.9104 0.8018]
50/100: train_loss=[0.28695306 0.5311012 ], train_acc=[0.90675 0.80225]
52/100: train_loss=[0.31040838 0.5251995 ], train_acc=[0.9023  0.80435]
54/100: train_loss=[0.2706132  0.52416325], train_acc=[0.9139  0.80425]
56/100: train_loss=[0.26920164 0.5277524 ], train_acc=[0.9144 0.8037]
58/100: train_loss=[0.29685804 0.5333754 ], train_acc=[0.90355 0.80445]
60/100: train_loss=[0.27623808 0.56637293], train_acc=[0.91165 0.789  ]
62/100: train_loss=[0.25888965 0.5510759 ], train_acc=[0.91825 0.7963 ]
64/100: train_loss=[0.26948085 0.52768487], train_acc=[0.9136  0.80545]
66/100: train_loss=[0.25496224 0.53011626], train_acc=[0.9191 0.8061]
68/100: train_loss=[0.26061004 0.5239799 ], train_acc=[0.9155  0.80455]
70/100: train_loss=[0.28353867 0.56278396], train_acc=[0.90635 0.7901 ]
72/100: train_loss=[0.25944576 0.5130285 ], train_acc=[0.9188  0.81405]
74/100: train_loss=[0.2529742 0.516096 ], train_acc=[0.9207  0.80835]
76/100: train_loss=[0.2589583 0.5078775], train_acc=[0.91755 0.8143 ]
78/100: train_loss=[0.2513523 0.503426 ], train_acc=[0.91975 0.8132 ]
80/100: train_loss=[0.25334126 0.5065869 ], train_acc=[0.92005 0.81315]
82/100: train_loss=[0.24766287 0.5096871 ], train_acc=[0.92185 0.81345]
84/100: train_loss=[0.25465772 0.5261093 ], train_acc=[0.9189  0.80375]
86/100: train_loss=[0.24839967 0.5137482 ], train_acc=[0.9216  0.80905]
88/100: train_loss=[0.24249157 0.50511724], train_acc=[0.9226  0.81365]
90/100: train_loss=[0.2492297  0.51551676], train_acc=[0.9205 0.8155]
92/100: train_loss=[0.23615633 0.5037743 ], train_acc=[0.92465 0.81395]
94/100: train_loss=[0.24324961 0.51687634], train_acc=[0.92085 0.8104 ]
96/100: train_loss=[0.25164032 0.5266521 ], train_acc=[0.9202  0.80445]
98/100: train_loss=[0.24217865 0.5188408 ], train_acc=[0.9251 0.8061]
100/100: train_loss=[0.238672  0.5088533], train_acc=[0.9241 0.8159]
**** Time taken for fashion_and_mnist_4 = 2082.1789717674255
**** Time taken for fashion_and_mnist = 10882.953276395798
